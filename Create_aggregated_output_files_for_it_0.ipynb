{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "688543d0",
   "metadata": {},
   "source": [
    "#### Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "597746a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matsim\n",
    "import os \n",
    "import pandas as pd\n",
    "#import plotly.express as px \n",
    "# AttributeError: module 'numpy' has no attribute 'bool8'\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly.subplots import make_subplots\n",
    "from collections import defaultdict\n",
    "import plotly\n",
    "import kaleido\n",
    "%matplotlib inline\n",
    "import plotly.io as pio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8ecc4a",
   "metadata": {},
   "source": [
    "#### Number of stuck time violations at iteration 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adf2ffd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of stuck vehicles\n",
    "def countStuckVehicles(pathToEvents):\n",
    "    events_file = pathToEvents\n",
    "    #\"/home/lola/math_cluster/output/output-lausitz-1pct-1-fCf_sCF_0.01_gS_default_3765/lausitz-1pct-1-fCf_sCf_0.01_gS_default_3765.output_events.xml.gz\"\n",
    "\n",
    "    #print(\"reading events:\", events_file)\n",
    "\n",
    "    # Read events - filter and return the listed event types only\n",
    "    events = matsim.event_reader(\n",
    "        events_file,\n",
    "        types=\"stuckAndContinue\",\n",
    "    )\n",
    "\n",
    "    stuck_person = defaultdict(list)\n",
    "\n",
    "    # Loop on all filtered events\n",
    "    for event in events:\n",
    "        if event[\"type\"] == \"stuckAndContinue\":\n",
    "            stuck_person[event[\"person\"]].append(event[\"legMode\"])\n",
    "    \n",
    "    count = 0 \n",
    "    for key in stuck_person.keys():\n",
    "        count+= len(stuck_person[key])\n",
    "    \n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b83288d",
   "metadata": {},
   "source": [
    "##### 1 pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "829bb5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "flowCapF = [\"0.01\"]\n",
    "storCapF =  [\"0.01\", \"0.03162\"]\n",
    "stuckTimes = [\"30.0\", \"3000.0\"]\n",
    "\n",
    "stuck_time_violations_1pct_it0 = pd.DataFrame()\n",
    "counter = 0\n",
    "for fCf in flowCapF:\n",
    "    for sCf in storCapF:\n",
    "        for sT in stuckTimes:\n",
    "            for sampleNr in range(1,11,1):\n",
    "                # declare path based on case \n",
    "                if((fCf == \"0.01\") & (sCf == \"0.01\") & (sT == \"30.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-1pct-\" + str(sampleNr) + \"-fCf_sCF_\" + sCf + \"_gS_default_3765/ITERS/it.0/lausitz-1pct-\" + str(sampleNr) + \"-fCf_sCf_0.01_gS_default_3765.0.events.xml.gz\"\n",
    "                    alpha = 1.0\n",
    "\n",
    "                elif((fCf == \"0.01\") & (sCf ==  \"0.03162\") & (sT == \"30.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-1pct-\" + str(sampleNr) + \"-fCf_\" + fCf + \"_sCF_\" + sCf + \"_gS_default_3765/ITERS/it.0/lausitz-1pct-\" + str(sampleNr) + \"-fCf_0.01_sCf_0.03162_gS_default_3765.0.events.xml.gz\"\n",
    "                    alpha = 0.75\n",
    "                \n",
    "                elif((fCf == \"0.01\") & (sCf == \"0.01\") & (sT == \"3000.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-1-pct-\" + str(sampleNr) + \"-fCf_sCF_\" + sCf  + \"_gS_4711_sT_\" + sT + \"_3765/ITERS/it.0/lausitz-1-pct-\" + str(sampleNr) + \"-fCf_sCF_0.01_gS_4711_sT_3000.0_3765.0.events.xml.gz\"\n",
    "                    alpha = 1.0\n",
    "\n",
    "                elif((fCf == \"0.01\") & (sCf ==  \"0.03162\") & (sT == \"3000.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-1-pct-\" + str(sampleNr) + \"-fCf_\" + fCf + \"_sCF_\" + sCf + \"_gS_4711_sT_\" + sT + \"_3765/ITERS/it.0/lausitz-1-pct-\" + str(sampleNr) + \"-fCf_0.01_sCF_0.03162_gS_4711_sT_3000.0_3765.0.events.xml.gz\"\n",
    "                    alpha = 0.75\n",
    "                else: \n",
    "                    print(\"case not found\")\n",
    "                    break\n",
    "                # count the number \n",
    "                stuck_veh = countStuckVehicles(path)\n",
    "                temp = pd.DataFrame({'n_stuck_veh': stuck_veh, 'sample_size': \"1-pct\", 'sample_nr': sampleNr, 'alpha' : alpha, 'stuck_time': float(sT), 'global_seed': \"default\"}, index = [counter])\n",
    "                stuck_time_violations_1pct_it0 = pd.concat([stuck_time_violations_1pct_it0, temp], axis = 0)\n",
    "                counter += 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d398ef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  1 pct random seed\n",
    "stuck_veh_1pct_rGs_it0 = pd.DataFrame()\n",
    "rGs = [ 4711,3254, 2306, 6384,4338, 6003, 5502, 9377, 5621, 9002 ]\n",
    "for seed in rGs:\n",
    "    if (seed == 4711):\n",
    "        # this case has alreade been counted\n",
    "        global_seed = \"rnd_\" + str(seed)\n",
    "        # insert number of stuck time violations from the first 1 pct sample\n",
    "        temp = {'n_stuck_veh': stuck_time_violations_1pct_it0[\"n_stuck_veh\"].iloc[0], 'sample_size': '1-pct', 'sample_nr': 1, 'alpha': 1.0, 'stuck_time': 30.0, 'global_seed': global_seed  }\n",
    "        temp = pd.DataFrame(data=temp, index=[rGs.index(4711)])\n",
    "        stuck_veh_1pct_rGs_it0 = pd.concat([stuck_veh_1pct_rGs_it0, temp])\n",
    "    \n",
    "    elif (seed == 3254):\n",
    "        path =\"/home/lola/math_cluster/output/output-lausitz-1pct-1-fCf_sCF_0.01_gS_3254_3765/ITERS/it.0/lausitz-1pct-1-fCf_sCf_0.01_gS_3254_3765.0.events.xml.gz\"\n",
    "        stuck_veh = countStuckVehicles(path)\n",
    "        temp1 = pd.DataFrame({'n_stuck_veh': stuck_veh, 'sample_size': '1-pct', 'sample_nr': 1, 'alpha': 1.0, 'stuck_time': 30.0, 'global_seed': \"rnd_\" + str(seed)  }, index = [rGs.index(3254)])\n",
    "        stuck_veh_1pct_rGs_it0 = pd.concat([stuck_veh_1pct_rGs_it0, temp1], axis = 0)\n",
    "    else:\n",
    "        path = \"/home/lola/math_cluster/output/output-lausitz-1.0-pct-1-fCf_sCF_0.01_gS_\" + str(seed) + \"_3765/ITERS/it.0/lausitz-1.0-pct-1-fCf_sCF_0.01_gS_\" + str(seed) + \"_3765.0.events.xml.gz\"\n",
    "        stuck_veh = countStuckVehicles(path)\n",
    "        temp2 = pd.DataFrame({'n_stuck_veh': stuck_veh, 'sample_size': '1-pct', 'sample_nr': 1, 'alpha': 1.0, 'stuck_time': 30.0, 'global_seed': \"rnd_\" + str(seed)  }, index = [rGs.index(seed)] )\n",
    "        stuck_veh_1pct_rGs_it0 = pd.concat([stuck_veh_1pct_rGs_it0, temp2], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9520f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stuck_time_violations_1pct_it0 = pd.concat([stuck_time_violations_1pct_it0, stuck_veh_1pct_rGs_it0], axis = 0, ignore_index= True)\n",
    "stuck_time_violations_1pct_it0.to_csv('/home/lola/Nextcloud/Masterarbeit/03_Outputs/stuck_time_violations_1_pct_it0.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756245a1",
   "metadata": {},
   "source": [
    "##### 5 pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123ccab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "flowCapF = [\"0.05\"]\n",
    "storCapF =  [\"0.05\", \"0.10574\"]\n",
    "stuckTimes = [\"30.0\", \"600.0\"]\n",
    "\n",
    "stuck_time_violations_5pct_it0 = pd.DataFrame()\n",
    "counter = 0\n",
    "for fCf in flowCapF:\n",
    "    for sCf in storCapF:\n",
    "        for sT in stuckTimes:\n",
    "            for sampleNr in range(1,11,1):\n",
    "                # declare path based on case \n",
    "                if((fCf == \"0.05\") & (sCf == \"0.05\") & (sT == \"30.0\")):\n",
    "                    if (sampleNr == 6):\n",
    "                        path  = \"/home/lola/math_cluster/output/output-lausitz-5.0-pct-\" + str(sampleNr) + \"-fCf_sCF_\" + sCf + \"_gS_4711_3765/ITERS/it.0/lausitz-5.0-pct-6-fCf_sCF_0.05_gS_4711_3765-2.0.events.xml.gz\"\n",
    "                    else: \n",
    "                        path = \"/home/lola/math_cluster/output/output-lausitz-5.0-pct-\" + str(sampleNr) + \"-fCf_sCF_\" + sCf + \"_gS_4711_3765/ITERS/it.0/lausitz-5.0-pct-\" + str(sampleNr) + \"-fCf_sCF_0.05_gS_4711_3765.0.events.xml.gz\"\n",
    "                    alpha = 1.0\n",
    "                    \n",
    "                elif((fCf == \"0.05\") & (sCf ==  \"0.10574\") & (sT == \"30.0\")):\n",
    "                    if(sampleNr == 6):\n",
    "                        path = \"/home/lola/math_cluster/output/output-lausitz-5.0-pct-\" + str(sampleNr) + \"-fCf_\" + fCf + \"_sCF_\" + sCf + \"_gS_4711_3765/ITERS/it.0/lausitz-5.0-pct-6-fCf_0.05_sCF_0.10574_gS_4711_3765-2.0.events.xml.gz\"\n",
    "                    else:\n",
    "                        path = \"/home/lola/math_cluster/output/output-lausitz-5.0-pct-\" + str(sampleNr) + \"-fCf_\" + fCf + \"_sCF_\" + sCf + \"_gS_4711_3765/ITERS/it.0/lausitz-5.0-pct-\" + str(sampleNr) + \"-fCf_0.05_sCF_0.10574_gS_4711_3765.0.events.xml.gz\"\n",
    "                    alpha = 0.75\n",
    "                elif((fCf == \"0.05\") & (sCf == \"0.05\") & (sT == \"600.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-5-pct-\" + str(sampleNr) + \"-fCf_sCF_\" + sCf + \"_gS_4711_sT_\" + sT + \"_3765/ITERS/it.0/lausitz-5-pct-\" + str(sampleNr) + \"-fCf_sCF_0.05_gS_4711_sT_600.0_3765.0.events.xml.gz\"\n",
    "                    alpha = 1.0\n",
    "                elif((fCf == \"0.05\") & (sCf ==  \"0.10574\") & (sT == \"600.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-5-pct-\" + str(sampleNr) + \"-fCf_\" + fCf + \"_sCF_\" + sCf + \"_gS_4711_sT_\" + sT + \"_3765/ITERS/it.0/lausitz-5-pct-\" + str(sampleNr) + \"-fCf_0.05_sCF_0.10574_gS_4711_sT_600.0_3765.0.events.xml.gz\"\n",
    "                    alpha = 0.75\n",
    "                \n",
    "                else: \n",
    "                    print(\"case not found\")\n",
    "                    break\n",
    "                stuck_veh = countStuckVehicles(path)\n",
    "                temp = pd.DataFrame({'n_stuck_veh': stuck_veh, 'sample_size': \"5-pct\", 'sample_nr': sampleNr, 'alpha' : alpha, 'stuck_time': float(sT), 'global_seed': \"default\"}, index = [counter])\n",
    "                stuck_time_violations_5pct_it0 = pd.concat([stuck_time_violations_5pct_it0, temp], axis = 0)\n",
    "                counter += 1\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5eb9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 pct random global seed\n",
    "stuck_time_violations_5pct_it0_rGs = pd.DataFrame()\n",
    "rGs = [4711, 3254, 2306, 6384,4338, 6003, 5502, 9377, 5621, 9002 ]\n",
    "\n",
    "for seed in rGs:\n",
    "    if (seed ==4711):\n",
    "        global_seed = \"rnd_\" + str(seed)\n",
    "        temp = {'n_stuck_veh': stuck_time_violations_5pct_it0[\"n_stuck_veh\"].iloc[0], 'sample_size': '5-pct', \"sample_nr\": 1, 'alpha': 1.0, 'stuck_time': 30.0, 'global_seed': global_seed  }\n",
    "        temp = pd.DataFrame(data=temp, index=[rGs.index(4711)])\n",
    "        stuck_time_violations_5pct_it0_rGs = pd.concat([stuck_time_violations_5pct_it0_rGs, temp])\n",
    "    else:\n",
    "        global_seed = \"rnd_\" + str(seed)\n",
    "        path = \"/home/lola/math_cluster/output/output-lausitz-5.0-pct-1-fCf_sCF_0.05_gS_\" + str(seed) + \"_3765/ITERS/it.0/lausitz-5.0-pct-1-fCf_sCF_0.05_gS_\" + str(seed) + \"_3765.0.events.xml.gz\"\n",
    "        stuck_veh = countStuckVehicles(path)\n",
    "        temp = pd.DataFrame({'n_stuck_veh': stuck_veh, 'sample_size': \"5-pct\", 'sample_nr': sampleNr, 'alpha' : 1.0, 'stuck_time': 30.0, 'global_seed': global_seed}, index = [counter])\n",
    "        stuck_time_violations_5pct_it0_rGs = pd.concat([stuck_time_violations_5pct_it0_rGs, temp], axis = 0)\n",
    "        counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dd3f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat and write output file\n",
    "stuck_time_violations_5pct_it0 = pd.concat([stuck_time_violations_5pct_it0, stuck_time_violations_5pct_it0_rGs], axis = 0, ignore_index= True)\n",
    "stuck_time_violations_5pct_it0.to_csv('/home/lola/Nextcloud/Masterarbeit/03_Outputs/stuck_time_violations_5_pct_it0.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae322c1",
   "metadata": {},
   "source": [
    "##### 10 pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "681a880d",
   "metadata": {},
   "outputs": [],
   "source": [
    "flowCapF = [\"0.1\"]\n",
    "storCapF =  [\"0.1\", \"0.17783\"]\n",
    "stuckTimes = [\"30.0\", \"300.0\"]\n",
    "\n",
    "stuck_time_violations_10pct_it0 = pd.DataFrame()\n",
    "counter = 0\n",
    "for fCf in flowCapF:\n",
    "    for sCf in storCapF:\n",
    "        for sT in stuckTimes:\n",
    "            for sampleNr in range(1,11,1):\n",
    "                # declare path based on case \n",
    "                if((fCf == \"0.1\") & (sCf == \"0.1\") & (sT == \"30.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-10.0-pct-\" + str(sampleNr) + \"-fCf_sCF_\" + sCf + \"_gS_4711_3765/ITERS/it.0/lausitz-10.0-pct-\" + str(sampleNr) + \"-fCf_sCF_0.1_gS_4711_3765.0.events.xml.gz\"\n",
    "                    alpha = 1.0       \n",
    "                elif((fCf == \"0.1\") & (sCf ==  \"0.17783\") & (sT == \"30.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-10.0-pct-\" + str(sampleNr) + \"-fCf_\" + fCf + \"_sCF_\" + sCf + \"_gS_4711_3765/ITERS/it.0/lausitz-10.0-pct-\" + str(sampleNr) + \"-fCf_0.1_sCF_0.17783_gS_4711_3765.0.events.xml.gz\"\n",
    "                    alpha = 0.75\n",
    "                elif((fCf == \"0.1\") & (sCf == \"0.1\") & (sT == \"300.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-10-pct-\" + str(sampleNr) + \"-fCf_sCF_\" + sCf + \"_gS_4711_sT_\" + sT + \"_3765/ITERS/it.0/lausitz-10-pct-\" + str(sampleNr) + \"-fCf_sCF_0.1_gS_4711_sT_300.0_3765.0.events.xml.gz\"\n",
    "                    alpha = 1.0\n",
    "                elif((fCf == \"0.1\") & (sCf ==  \"0.17783\") & (sT == \"300.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-10-pct-\" + str(sampleNr) + \"-fCf_\" + fCf + \"_sCF_\" + sCf + \"_gS_4711_sT_\" + sT + \"_3765/ITERS/it.0/lausitz-10-pct-\" + str(sampleNr) + \"-fCf_0.1_sCF_0.17783_gS_4711_sT_300.0_3765.0.events.xml.gz\"\n",
    "                    alpha = 0.75  \n",
    "                else: \n",
    "                    print(\"case not found\")\n",
    "                    break\n",
    "                stuck_veh = countStuckVehicles(path)\n",
    "                temp = pd.DataFrame({'n_stuck_veh': stuck_veh, 'sample_size': \"10-pct\", 'sample_nr': sampleNr, 'alpha' : alpha, 'stuck_time': float(sT), 'global_seed': \"default\"}, index = [counter])\n",
    "                stuck_time_violations_10pct_it0 = pd.concat([stuck_time_violations_10pct_it0, temp], axis = 0)\n",
    "                counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6ffc4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write output file\n",
    "stuck_time_violations_10pct_it0.to_csv('/home/lola/Nextcloud/Masterarbeit/03_Outputs/stuck_time_violations_10_pct_it0.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb16413d",
   "metadata": {},
   "source": [
    "##### 25 pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0d2dee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "flowCapF = [\"0.25\"]\n",
    "storCapF =  [\"0.25\", \"0.35355\"]\n",
    "stuckTimes = [\"30.0\", \"120.0\"]\n",
    "\n",
    "stuck_time_violations_25pct_it0 = pd.DataFrame()\n",
    "counter = 0\n",
    "for fCf in flowCapF:\n",
    "    for sCf in storCapF:\n",
    "        for sT in stuckTimes:\n",
    "            for sampleNr in range(1,2,1):\n",
    "                # declare path based on case \n",
    "                if((fCf == \"0.25\") & (sCf == \"0.25\") & (sT == \"30.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-25.0-pct-fCf_sCF_\" + sCf + \"_gS_4711_3765/ITERS/it.0/lausitz-25.0-pct-fCf_sCF_0.25_gS_4711_3765.0.events.xml.gz\"\n",
    "                    alpha = 1.0      \n",
    "                elif((fCf == \"0.25\") & (sCf ==  \"0.35355\") & (sT == \"30.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-25.0-pct-fCf_\" + fCf + \"_sCF_\" + sCf + \"_gS_4711_3765/ITERS/it.0/lausitz-25.0-pct-fCf_0.25_sCF_0.35355_gS_4711_3765.0.events.xml.gz\"\n",
    "                    alpha  = 0.75\n",
    "                elif((fCf == \"0.25\") & (sCf == \"0.25\") & (sT == \"120.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-25-pct-\" + str(sampleNr) + \"-fCf_sCF_\" + fCf + \"_gS_4711_sT_\" + sT + \"_3765/ITERS/it.0/lausitz-25-pct-1-fCf_sCF_0.25_gS_4711_sT_120.0_3765.0.events.xml.gz\"\n",
    "                    alpha = 1.0\n",
    "                elif((fCf == \"0.25\") & (sCf ==  \"0.35355\") & (sT == \"120.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-25-pct-\" + str(sampleNr) + \"-fCf_\" + fCf + \"_sCF_\" + sCf + \"_gS_4711_sT_\" + sT + \"_3765/ITERS/it.0/lausitz-25-pct-1-fCf_0.25_sCF_0.35355_gS_4711_sT_120.0_3765.0.events.xml.gz\" \n",
    "                    alpha = 0.75\n",
    "                else: \n",
    "                    print(\"case not found\")\n",
    "                    break\n",
    "                stuck_veh = countStuckVehicles(path)\n",
    "                temp = pd.DataFrame({'n_stuck_veh': stuck_veh, 'sample_size': \"25-pct\", 'sample_nr': sampleNr, 'alpha' : alpha, 'stuck_time': float(sT), 'global_seed': \"default\"}, index = [counter])\n",
    "                stuck_time_violations_25pct_it0 = pd.concat([stuck_time_violations_25pct_it0, temp], axis = 0)\n",
    "                counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26703802",
   "metadata": {},
   "outputs": [],
   "source": [
    "stuck_time_violations_25pct_it0.to_csv('/home/lola/Nextcloud/Masterarbeit/03_Outputs/stuck_time_violations_25_pct_it0.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9c06c3",
   "metadata": {},
   "source": [
    "##### 50 pct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28439335",
   "metadata": {},
   "outputs": [],
   "source": [
    "flowCapF = [\"0.5\"]\n",
    "storCapF =  [\"0.5\", \"0.5946\"]\n",
    "stuckTimes = [\"30.0\", \"60.0\"]\n",
    "\n",
    "stuck_time_violations_50pct_it0 = pd.DataFrame()\n",
    "counter = 0\n",
    "for fCf in flowCapF:\n",
    "    for sCf in storCapF:\n",
    "        for sT in stuckTimes:\n",
    "            for sampleNr in range(1,2,1):\n",
    "                # declare path based on case \n",
    "                if((fCf == \"0.5\") & (sCf == \"0.5\") & (sT == \"30.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-50.0-pct-fCf_sCF_0.5_gS_4711_3765/ITERS/it.0/lausitz-50.0-pct-fCf_sCF_0.5_gS_4711_3765.0.events.xml.gz\"\n",
    "                    alpha = 1.0       \n",
    "                elif((fCf == \"0.5\") & (sCf ==  \"0.5946\") & (sT == \"30.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-50.0-pct-fCf_0.5_sCF_0.5946_gS_4711_3765/ITERS/it.0/lausitz-50.0-pct-fCf_0.5_sCF_0.5946_gS_4711_3765.0.events.xml.gz\"\n",
    "                    alpha = 0.75\n",
    "                elif((fCf == \"0.5\") & (sCf == \"0.5\") & (sT == \"60.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-50-pct-1-fCf_sCF_0.5_gS_4711_sT_60.0_3765/ITERS/it.0/lausitz-50-pct-1-fCf_sCF_0.5_gS_4711_sT_60.0_3765.0.events.xml.gz\"\n",
    "                    alpha = 1.0\n",
    "                elif((fCf == \"0.5\") & (sCf ==  \"0.5946\") & (sT == \"60.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-50-pct-1-fCf_0.5_sCF_0.5946_gS_4711_sT_60.0_3765/ITERS/it.0/lausitz-50-pct-1-fCf_0.5_sCF_0.5946_gS_4711_sT_60.0_3765.0.events.xml.gz\"\n",
    "                    alpha = 0.75 \n",
    "                else: \n",
    "                    print(\"case not found\")\n",
    "                    break\n",
    "                stuck_veh = countStuckVehicles(path)\n",
    "                temp = pd.DataFrame({'n_stuck_veh': stuck_veh, 'sample_size': \"50-pct\", 'sample_nr': sampleNr, 'alpha' : alpha, 'stuck_time': float(sT), 'global_seed': \"default\"}, index = [counter])\n",
    "                stuck_time_violations_50pct_it0 = pd.concat([stuck_time_violations_50pct_it0, temp], axis = 0)\n",
    "                counter += 1\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff422864",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/lola/Nextcloud/Masterarbeit/03_Outputs_From_RunsLausitz/output-lausitz-25-pct-doubled-fCf_0.5_sCF_0.5_gS_4711_3765/ITERS/it.0/lausitz-25-pct-doubled-fCf_0.5_sCF_0.5_gS_4711__3765.0.events.xml.gz\"\n",
    "stuck_veh = countStuckVehicles(path)\n",
    "temp = pd.DataFrame({'n_stuck_veh': stuck_veh, 'sample_size': \"25-pct-doubled\", 'sample_nr': 1, 'alpha' : 1.0, 'stuck_time': 30.0, 'global_seed': \"default\"}, index = [counter])\n",
    "stuck_time_violations_50pct_it0 = pd.concat([stuck_time_violations_50pct_it0, temp], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "abb9e991",
   "metadata": {},
   "outputs": [],
   "source": [
    "stuck_time_violations_50pct_it0.to_csv('/home/lola/Nextcloud/Masterarbeit/03_Outputs/stuck_time_violations_50_pct_it0.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb506974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_stuck_veh</th>\n",
       "      <th>sample_size</th>\n",
       "      <th>sample_nr</th>\n",
       "      <th>alpha</th>\n",
       "      <th>stuck_time</th>\n",
       "      <th>global_seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15224</td>\n",
       "      <td>50-pct</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>30.0</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15137</td>\n",
       "      <td>50-pct</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>60.0</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15126</td>\n",
       "      <td>50-pct</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>30.0</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15109</td>\n",
       "      <td>50-pct</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>60.0</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16258</td>\n",
       "      <td>25-pct-doubled</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>30.0</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_stuck_veh     sample_size  sample_nr  alpha  stuck_time global_seed\n",
       "0        15224          50-pct          1   1.00        30.0     default\n",
       "1        15137          50-pct          1   1.00        60.0     default\n",
       "2        15126          50-pct          1   0.75        30.0     default\n",
       "3        15109          50-pct          1   0.75        60.0     default\n",
       "4        16258  25-pct-doubled          1   1.00        30.0     default"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stuck_time_violations_50pct_it0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d829f6",
   "metadata": {},
   "source": [
    "##### 100 pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab7bef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "flowCapF = [\"1.0\"]\n",
    "storCapF =  [\"1.0\"]\n",
    "stuckTimes = [\"30.0\"]\n",
    "\n",
    "stuck_time_violations_100pct_it0 = pd.DataFrame()\n",
    "counter = 0\n",
    "for fCf in flowCapF:\n",
    "    for sCf in storCapF:\n",
    "        for sT in stuckTimes:\n",
    "            for sampleNr in range(1,2,1):\n",
    "                # declare path based on case \n",
    "                path = \"/home/lola/math_cluster/output/output-lausitz-100.0-pct-fCf_sCF_1.0_gS_4711_3765/ITERS/it.0/lausitz-100.0-pct-fCf_sCF_1.0_gS_4711_3765.0.events.xml.gz\"\n",
    "                stuck_veh = countStuckVehicles(path)\n",
    "                temp = pd.DataFrame({'n_stuck_veh': stuck_veh, 'sample_size': \"100-pct\", 'sample_nr': sampleNr, 'alpha' : 1.0, 'stuck_time': 30.0, 'global_seed': \"default\"}, index = [counter])\n",
    "                stuck_time_violations_100pct_it0 = pd.concat([stuck_time_violations_100pct_it0, temp], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fda975b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/lola/Nextcloud/Masterarbeit/03_Outputs_From_RunsLausitz/output-lausitz-25.0-pct-quadrupled-fCf_1.0_sCF_1.0_gS_4711_3765/ITERS/it.0/lausitz-25-pct-quadrupled-fCf_1.0_sCF_1.0_gS_4711__3765.0.events.xml.gz\"\n",
    "stuck_veh = countStuckVehicles(path)\n",
    "temp = pd.DataFrame({'n_stuck_veh': stuck_veh, 'sample_size': \"25-pct-quadrupled\", 'sample_nr': 1, 'alpha' : 1.0, 'stuck_time': 30.0, 'global_seed': \"default\"}, index = [counter])\n",
    "stuck_time_violations_100pct_it0 = pd.concat([stuck_time_violations_100pct_it0, temp], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6bdfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stuck_time_violations_100pct_it0.to_csv('/home/lola/Nextcloud/Masterarbeit/03_Outputs/stuck_time_violations_100pct_it0.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da143a9c",
   "metadata": {},
   "source": [
    "##### Concat and write output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74783648",
   "metadata": {},
   "outputs": [],
   "source": [
    "stuck_time_violations_1pct_it0 = pd.read_csv(\"/home/lola/Nextcloud/Masterarbeit/03_Outputs/stuck_time_violations_1_pct_it0.csv\")\n",
    "stuck_time_violations_5pct_it0 = pd.read_csv(\"/home/lola/Nextcloud/Masterarbeit/03_Outputs/stuck_time_violations_5_pct_it0.csv\")\n",
    "stuck_time_violations_10pct_it0 = pd.read_csv(\"/home/lola/Nextcloud/Masterarbeit/03_Outputs/stuck_time_violations_10_pct_it0.csv\")\n",
    "stuck_time_violations_25pct_it0 = pd.read_csv(\"/home/lola/Nextcloud/Masterarbeit/03_Outputs/stuck_time_violations_25_pct_it0.csv\")\n",
    "stuck_time_violations_50pct_it0 = pd.read_csv(\"/home/lola/Nextcloud/Masterarbeit/03_Outputs/stuck_time_violations_50_pct_it0.csv\")\n",
    "stuck_time_violations_100pct_it0 = pd.read_csv(\"/home/lola/Nextcloud/Masterarbeit/03_Outputs/stuck_time_violations_100_pct_it0.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1292c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat all\n",
    "stuck_time_violations_1_100_it_0= pd.concat([stuck_time_violations_1pct_it0, stuck_time_violations_5pct_it0, stuck_time_violations_10pct_it0, stuck_time_violations_25pct_it0, stuck_time_violations_50pct_it0, stuck_time_violations_100pct_it0 ], axis = 0)\n",
    "# write all to csv\n",
    "stuck_time_violations_1_100_it_0.to_csv(\"/home/lola/Nextcloud/Masterarbeit/03_Outputs/stuck_time_violations_1_100_it_0.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e08005a",
   "metadata": {},
   "source": [
    "#### Number of Link leave events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6d80bd",
   "metadata": {},
   "source": [
    "#### Executed Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b84e27",
   "metadata": {},
   "source": [
    "##### Original Plans, before Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889c399e",
   "metadata": {},
   "source": [
    "##### 1 pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7ac4b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### scores ####\n",
    "# 1pct, alpha = 1\n",
    "scores_1pct_beforeSim = pd.DataFrame()\n",
    "for sampleNr in range(1,11,1):\n",
    "    path = \"/home/lola/math_cluster/output/output-lausitz-1pct-\" + str(sampleNr) +\"-fCf_sCF_0.01_gS_default_3765/ITERS/it.0/lausitz-1pct-\" + str(sampleNr) + \"-fCf_sCf_0.01_gS_default_3765.0.plans.xml.gz\"\n",
    "    plans = matsim.plan_reader(path, selected_plans_only = True)\n",
    "    experienced_scores = []\n",
    "    id = []\n",
    "    for person, plan in plans:\n",
    "        experienced_scores.append(plan.attrib['score'])\n",
    "        id.append(person.attrib['id'])\n",
    "    experienced_scores = pd.DataFrame({'id': id, 'exp_score': pd.to_numeric(experienced_scores)})\n",
    "    average = np.mean(experienced_scores['exp_score'])\n",
    "    df = pd.DataFrame({\"avg_executed_it_0\": average, \"sample_size\": \"1-pct\", \"sample_nr\": sampleNr, \"alpha\": 1.0, \"stuck_time\": 30.0, \"global_seed\": \"default\" }, index = [sampleNr])\n",
    "    scores_1pct_beforeSim = pd.concat([scores_1pct_beforeSim, df], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147de120",
   "metadata": {},
   "source": [
    "##### 5 pct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7cb0b0",
   "metadata": {},
   "source": [
    "#### Iteration 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c50673",
   "metadata": {},
   "source": [
    "##### 1 pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42a3fb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### scores ####\n",
    "# 1pct, alpha = 1\n",
    "scores_1pct = pd.DataFrame()\n",
    "for elem in range(1,11,1):\n",
    "    path = \"/home/lola/math_cluster/output/output-lausitz-1pct-\" + str(elem) + \"-fCf_sCF_0.01_gS_default_3765/ITERS/it.0/lausitz-1pct-\" + str(elem) + \"-fCf_sCf_0.01_gS_default_3765.0.experienced_plans.xml.gz\"\n",
    "    plans = matsim.plan_reader(path, selected_plans_only = True)\n",
    "    experienced_scores = []\n",
    "    id = []\n",
    "    for person, plan in plans:\n",
    "        experienced_scores.append(plan.attrib['score'])\n",
    "        id.append(person.attrib['id'])\n",
    "    experienced_scores = pd.DataFrame({'id': id, 'exp_score': pd.to_numeric(experienced_scores)})\n",
    "    average = np.mean(experienced_scores['exp_score'])\n",
    "    df = pd.DataFrame({\"avg_executed_it_0\": average, \"sample_size\": \"1-pct\", \"sample_nr\": elem, \"alpha\": 1.0, \"stuck_time\": 30.0, \"global_seed\": \"default\" }, index = [elem])\n",
    "    scores_1pct = pd.concat([scores_1pct, df], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7273be3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 pct, alpha = 0.75\n",
    "scores_1pct_sCf = pd.DataFrame()\n",
    "for elem in range(1,11,1):\n",
    "    # /home/lola/math_cluster/output/output-lausitz-1pct-1-fCf_0.01_sCF_0.03162_gS_default_3765/ITERS/it.0/lausitz-1pct-1-fCf_0.01_sCf_0.03162_gS_default_3765.0.experienced_plans.xml.gz\n",
    "    path = \"/home/lola/math_cluster/output/output-lausitz-1pct-\" +str(elem) + \"-fCf_0.01_sCF_0.03162_gS_default_3765/ITERS/it.0/lausitz-1pct-\" + str(elem) + \"-fCf_0.01_sCf_0.03162_gS_default_3765.0.experienced_plans.xml.gz\"\n",
    "    plans = matsim.plan_reader(path, selected_plans_only = True)\n",
    "    experienced_scores = []\n",
    "    id = []\n",
    "    for person, plan in plans:\n",
    "        experienced_scores.append(plan.attrib['score'])\n",
    "        id.append(person.attrib['id'])\n",
    "    experienced_scores = pd.DataFrame({'id': id, 'exp_score': pd.to_numeric(experienced_scores)})\n",
    "    average = np.mean(experienced_scores['exp_score'])\n",
    "    df = pd.DataFrame({\"avg_executed_it_0\":average, \"sample_size\": \"1-pct\", \"sample_nr\": elem, \"alpha\": 0.75, \"stuck_time\": 30.0, \"global_seed\": \"default\" }, index = [elem])\n",
    "    scores_1pct_sCf = pd.concat([scores_1pct_sCf, df], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0556de11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 pct, alpha 1, random global seed\n",
    "#  1 pct random seed\n",
    "scores_1pct_rGs = pd.DataFrame()\n",
    "rGs = [ 4711,3254, 2306, 6384,4338, 6003, 5502, 9377, 5621, 9002 ]\n",
    "for seed in rGs:\n",
    "    if (seed == 4711):\n",
    "        global_seed = \"rnd_\" + str(seed)\n",
    "        # insert number of stuck time violations from the first 1 pct sample\n",
    "        df = pd.DataFrame({\"avg_executed_it_0\":scores_1pct[\"avg_executed_it_0\"].iloc[0], \"sample_size\": \"1-pct\", \"sample_nr\": 1, \"alpha\": 1.0, \"stuck_time\": 30.0, \"global_seed\": global_seed }, index = [rGs.index(seed)])\n",
    "        scores_1pct_rGs = pd.concat([scores_1pct_rGs, df], axis = 0)\n",
    "    \n",
    "    elif (seed == 3254):\n",
    "        global_seed = \"rnd_\" + str(seed)\n",
    "        path =\"/home/lola/math_cluster/output/output-lausitz-1pct-1-fCf_sCF_0.01_gS_3254_3765/ITERS/it.0/lausitz-1pct-1-fCf_sCf_0.01_gS_3254_3765.0.experienced_plans.xml.gz\"\n",
    "        plans = matsim.plan_reader(path, selected_plans_only = True)\n",
    "        experienced_scores = []\n",
    "        for person, plan in plans:\n",
    "            experienced_scores.append(plan.attrib['score'])\n",
    "\n",
    "        experienced_scores = pd.DataFrame({'exp_score': pd.to_numeric(experienced_scores)})\n",
    "        average = np.mean(experienced_scores['exp_score'])\n",
    "        df = pd.DataFrame({\"avg_executed_it_0\":average, \"sample_size\": \"1-pct\", \"sample_nr\": 1, \"alpha\": 1.0, \"stuck_time\": 30.0, \"global_seed\": global_seed}, index = [rGs.index(seed)])\n",
    "        scores_1pct_rGs = pd.concat([scores_1pct_rGs, df], axis = 0)\n",
    "    else:\n",
    "        global_seed = \"rnd_\" + str(seed)\n",
    "        # /home/lola/math_cluster/output/output-lausitz-1.0-pct-1-fCf_sCF_0.01_gS_6003_3765/ITERS/it.0/lausitz-1.0-pct-1-fCf_sCF_0.01_gS_6003_3765.0.experienced_plans.xml.gz\n",
    "        path = \"/home/lola/math_cluster/output/output-lausitz-1.0-pct-1-fCf_sCF_0.01_gS_\" + str(seed) + \"_3765/ITERS/it.0/lausitz-1.0-pct-1-fCf_sCF_0.01_gS_\" + str(seed) + \"_3765.0.experienced_plans.xml.gz\"\n",
    "        plans = matsim.plan_reader(path, selected_plans_only = True)\n",
    "        experienced_scores = []\n",
    "        for person, plan in plans:\n",
    "            experienced_scores.append(plan.attrib['score'])\n",
    "        \n",
    "        experienced_scores = pd.DataFrame({'exp_score': pd.to_numeric(experienced_scores)})\n",
    "        average = np.mean(experienced_scores['exp_score'])\n",
    "        df = pd.DataFrame({\"avg_executed_it_0\":average, \"sample_size\": \"1-pct\", \"sample_nr\": 1, \"alpha\": 1.0, \"stuck_time\": 30.0, \"global_seed\": global_seed}, index = [rGs.index(seed)])\n",
    "        scores_1pct_rGs = pd.concat([scores_1pct_rGs, df], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01a9e730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 pct, alpha = 1, sT scaled\n",
    "scores_1pct_sT =pd.DataFrame()\n",
    "for elem in range(1,11,1):\n",
    "    path = \"/home/lola/math_cluster/output/output-lausitz-1-pct-\" + str(elem) + \"-fCf_sCF_0.01_gS_4711_sT_3000.0_3765/ITERS/it.0/lausitz-1-pct-\" + str(elem) + \"-fCf_sCF_0.01_gS_4711_sT_3000.0_3765.0.experienced_plans.xml.gz\"\n",
    "    plans = matsim.plan_reader(path, selected_plans_only = True)\n",
    "    experienced_scores = []\n",
    "    for person, plan in plans:\n",
    "        experienced_scores.append(plan.attrib['score'])\n",
    "    experienced_scores = pd.DataFrame({'exp_score': pd.to_numeric(experienced_scores)})\n",
    "    average = np.mean(experienced_scores['exp_score'])\n",
    "    df = pd.DataFrame({\"avg_executed_it_0\": average, \"sample_size\": \"1-pct\", \"sample_nr\": elem, \"alpha\": 1.0, \"stuck_time\": 3000.0, \"global_seed\": \"default\" }, index = [elem])\n",
    "    scores_1pct_sT = pd.concat([scores_1pct_sT, df], axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09d911dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 pct, alpha = 0.75, sT scaled\n",
    "scores_1pct_sT_sCf =pd.DataFrame()\n",
    "for elem in range(1,11,1):\n",
    "    path = \"/home/lola/math_cluster/output/output-lausitz-1-pct-\" + str(elem) + \"-fCf_0.01_sCF_0.03162_gS_4711_sT_3000.0_3765/ITERS/it.0/lausitz-1-pct-\" + str(elem) + \"-fCf_0.01_sCF_0.03162_gS_4711_sT_3000.0_3765.0.experienced_plans.xml.gz\"\n",
    "    plans = matsim.plan_reader(path, selected_plans_only = True)\n",
    "    experienced_scores = []\n",
    "    for person, plan in plans:\n",
    "        experienced_scores.append(plan.attrib['score'])\n",
    "    experienced_scores = pd.DataFrame({'exp_score': pd.to_numeric(experienced_scores)})\n",
    "    average = np.mean(experienced_scores['exp_score'])\n",
    "    df = pd.DataFrame({\"avg_executed_it_0\": average, \"sample_size\": \"1-pct\", \"sample_nr\": elem, \"alpha\": 0.75, \"stuck_time\": 3000.0, \"global_seed\": \"default\" }, index = [elem])\n",
    "    scores_1pct_sT_sCf = pd.concat([scores_1pct_sT_sCf, df], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ad1f467",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_1pct_all_it0 = pd.concat([scores_1pct, scores_1pct_sCf, scores_1pct_rGs, scores_1pct_sT, scores_1pct_sT_sCf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa1ff3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_1pct_all_it0.to_csv('/home/lola/Nextcloud/Masterarbeit/03_Outputs/exp_scores_all_1pct_samples_it0.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d18710",
   "metadata": {},
   "source": [
    "##### 5 pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2015c293",
   "metadata": {},
   "outputs": [],
   "source": [
    "flowCapF = [\"0.05\"]\n",
    "storCapF =  [\"0.05\", \"0.10574\"]\n",
    "stuckTimes = [\"30.0\", \"600.0\"]\n",
    "\n",
    "scores_5pct = pd.DataFrame()\n",
    "counter = 0\n",
    "for fCf in flowCapF:\n",
    "    for sCf in storCapF:\n",
    "        for sT in stuckTimes:\n",
    "            for sampleNr in range(1,11,1):\n",
    "                # declare path based on case \n",
    "                if((fCf == \"0.05\") & (sCf == \"0.05\") & (sT == \"30.0\")):\n",
    "                    if (sampleNr == 6):\n",
    "                        path  = \"/home/lola/math_cluster/output/output-lausitz-5.0-pct-6-fCf_sCF_0.05_gS_4711_3765/ITERS/it.0/lausitz-5.0-pct-6-fCf_sCF_0.05_gS_4711_3765-2.0.experienced_plans.xml.gz\"\n",
    "                    else: \n",
    "                        path = \"/home/lola/math_cluster/output/output-lausitz-5.0-pct-\" + str(sampleNr) + \"-fCf_sCF_0.05_gS_4711_3765/ITERS/it.0/lausitz-5.0-pct-\" + str(sampleNr) + \"-fCf_sCF_0.05_gS_4711_3765.0.experienced_plans.xml.gz\"\n",
    "                    \n",
    "                elif((fCf == \"0.05\") & (sCf ==  \"0.10574\") & (sT == \"30.0\")):\n",
    "                    if(sampleNr == 6):\n",
    "                        path = \"/home/lola/math_cluster/output/output-lausitz-5.0-pct-6-fCf_0.05_sCF_0.10574_gS_4711_3765/ITERS/it.0/lausitz-5.0-pct-6-fCf_0.05_sCF_0.10574_gS_4711_3765-2.0.experienced_plans.xml.gz\"\n",
    "                    else:\n",
    "                        path = \"/home/lola/math_cluster/output/output-lausitz-5.0-pct-\" + str(sampleNr) + \"-fCf_0.05_sCF_0.10574_gS_4711_3765/ITERS/it.0/lausitz-5.0-pct-\" + str(sampleNr) + \"-fCf_0.05_sCF_0.10574_gS_4711_3765.0.experienced_plans.xml.gz\"\n",
    "                elif((fCf == \"0.05\") & (sCf == \"0.05\") & (sT == \"600.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-5-pct-\"+ str(sampleNr) + \"-fCf_sCF_0.05_gS_4711_sT_600.0_3765/ITERS/it.0/lausitz-5-pct-\" + str(sampleNr) + \"-fCf_sCF_0.05_gS_4711_sT_600.0_3765.0.experienced_plans.xml.gz\"\n",
    "                elif((fCf == \"0.05\") & (sCf ==  \"0.10574\") & (sT == \"600.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-5-pct-\" + str(sampleNr) + \"-fCf_0.05_sCF_0.10574_gS_4711_sT_600.0_3765/ITERS/it.0/lausitz-5-pct-\" + str(sampleNr) + \"-fCf_0.05_sCF_0.10574_gS_4711_sT_600.0_3765.0.experienced_plans.xml.gz\"\n",
    "                \n",
    "                else: \n",
    "                    print(\"case not found\")\n",
    "                    break\n",
    "                # read experienced plans file\n",
    "                plans = matsim.plan_reader(path, selected_plans_only = True)\n",
    "                # create list to store scores in\n",
    "                experienced_scores = []\n",
    "                # store all executed scores from plans file in list\n",
    "                for person, plan in plans:\n",
    "                    experienced_scores.append(plan.attrib['score'])\n",
    "                experienced_scores = pd.DataFrame({'exp_score': pd.to_numeric(experienced_scores)})\n",
    "                # calculate average of these scores\n",
    "                average = np.mean(experienced_scores['exp_score'])\n",
    "                if (sCf == \"0.10574\"): \n",
    "                    alpha = 0.75\n",
    "                elif( sCf == \"0.05\"):\n",
    "                    alpha = 1.0\n",
    "                # create df for specific case and store it in scores_5pct\n",
    "                df = pd.DataFrame({\"avg_executed_it_0\": average, \"sample_size\": \"5-pct\", \"sample_nr\": sampleNr, \"alpha\": alpha, \"stuck_time\": float(sT), \"global_seed\": \"default\" }, index = [counter])\n",
    "                scores_5pct = pd.concat([scores_5pct, df], axis = 0)\n",
    "                counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2afb29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 pct random global seed\n",
    "scores_5pct_rGs = pd.DataFrame()\n",
    "rGs = [4711, 3254, 2306, 6384,4338, 6003, 5502, 9377, 5621, 9002 ]\n",
    "\n",
    "for seed in rGs:\n",
    "    if (seed ==4711):\n",
    "        global_seed = \"rnd_\" + str(seed)\n",
    "        temp = {'avg_executed_it_0': scores_5pct[\"avg_executed_it_0\"].iloc[0], 'sample_size': '5-pct', \"sample_nr\": 1, 'alpha': 1.0, 'stuck_time': 30.0, 'global_seed': global_seed  }\n",
    "        temp = pd.DataFrame(data=temp, index=[rGs.index(4711)])\n",
    "        scores_5pct_rGs = pd.concat([scores_5pct_rGs, temp])\n",
    "    else:\n",
    "        global_seed = \"rnd_\" + str(seed)\n",
    "        path = \"/home/lola/math_cluster/output/output-lausitz-5.0-pct-1-fCf_sCF_0.05_gS_\"+ str(seed) + \"_3765/ITERS/it.0/lausitz-5.0-pct-1-fCf_sCF_0.05_gS_\" + str(seed) + \"_3765.0.experienced_plans.xml.gz\"\n",
    "        plans = matsim.plan_reader(path, selected_plans_only = True)\n",
    "        experienced_scores = []\n",
    "        for person, plan in plans:\n",
    "            experienced_scores.append(plan.attrib['score'])\n",
    "        experienced_scores = pd.DataFrame({'exp_score': pd.to_numeric(experienced_scores)})\n",
    "        average = np.mean(experienced_scores['exp_score'])\n",
    "        temp = {'avg_executed_it_0': average, 'sample_size': '5-pct', \"sample_nr\": 1, 'alpha': 1.0, 'stuck_time': 30.0, 'global_seed': global_seed  }\n",
    "        df = pd.DataFrame(data=temp, index=[rGs.index(seed)])\n",
    "        scores_5pct_rGs = pd.concat([scores_5pct_rGs, df], axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6455e67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat dfs\n",
    "scores_5pct_all_it0 = pd.concat([scores_5pct, scores_5pct_rGs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38283bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write csv\n",
    "scores_5pct_all_it0.to_csv(\"/home/lola/Nextcloud/Masterarbeit/03_Outputs/exp_scores_all_5pct_samples_it0.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d586b57",
   "metadata": {},
   "source": [
    "##### 10 pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88783942",
   "metadata": {},
   "outputs": [],
   "source": [
    "flowCapF = [\"0.1\"]\n",
    "storCapF =  [\"0.1\", \"0.17783\"]\n",
    "stuckTimes = [\"30.0\", \"300.0\"]\n",
    "\n",
    "scores_10pct = pd.DataFrame()\n",
    "counter = 0\n",
    "for fCf in flowCapF:\n",
    "    for sCf in storCapF:\n",
    "        for sT in stuckTimes:\n",
    "            for sampleNr in range(1,11,1):\n",
    "                # declare path based on case \n",
    "                if((fCf == \"0.1\") & (sCf == \"0.1\") & (sT == \"30.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-10.0-pct-\" + str(sampleNr) + \"-fCf_sCF_0.1_gS_4711_3765/ITERS/it.0/lausitz-10.0-pct-\" + str(sampleNr) + \"-fCf_sCF_0.1_gS_4711_3765.0.experienced_plans.xml.gz\"       \n",
    "                elif((fCf == \"0.1\") & (sCf ==  \"0.17783\") & (sT == \"30.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-10.0-pct-\" + str(sampleNr) + \"-fCf_0.1_sCF_0.17783_gS_4711_3765/ITERS/it.0/lausitz-10.0-pct-\" + str(sampleNr) + \"-fCf_0.1_sCF_0.17783_gS_4711_3765.0.experienced_plans.xml.gz\"\n",
    "                elif((fCf == \"0.1\") & (sCf == \"0.1\") & (sT == \"300.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-10-pct-\" + str(sampleNr) + \"-fCf_sCF_0.1_gS_4711_sT_300.0_3765/ITERS/it.0/lausitz-10-pct-\" + str(sampleNr) + \"-fCf_sCF_0.1_gS_4711_sT_300.0_3765.0.experienced_plans.xml.gz\"\n",
    "                elif((fCf == \"0.1\") & (sCf ==  \"0.17783\") & (sT == \"300.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-10-pct-\" + str(sampleNr) + \"-fCf_0.1_sCF_0.17783_gS_4711_sT_300.0_3765/ITERS/it.0/lausitz-10-pct-\" + str(sampleNr) + \"-fCf_0.1_sCF_0.17783_gS_4711_sT_300.0_3765.0.experienced_plans.xml.gz\"  \n",
    "                else: \n",
    "                    print(\"case not found\")\n",
    "                    break\n",
    "                # read experienced plans file\n",
    "                plans = matsim.plan_reader(path, selected_plans_only = True)\n",
    "                # create list to store scores in\n",
    "                experienced_scores = []\n",
    "                # store all executed scores from plans file in list\n",
    "                for person, plan in plans:\n",
    "                    experienced_scores.append(plan.attrib['score'])\n",
    "                experienced_scores = pd.DataFrame({'exp_score': pd.to_numeric(experienced_scores)})\n",
    "                # calculate average of these scores\n",
    "                average = np.mean(experienced_scores['exp_score'])\n",
    "                if (sCf == \"0.17783\"): \n",
    "                    alpha = 0.75\n",
    "                elif( sCf == \"0.1\"):\n",
    "                    alpha = 1.0\n",
    "                # create df for specific case and store it in scores_10pct\n",
    "                df = pd.DataFrame({\"avg_executed_it_0\": average, \"sample_size\": \"10-pct\", \"sample_nr\": sampleNr, \"alpha\": alpha, \"stuck_time\": float(sT), \"global_seed\": \"default\" }, index = [counter])\n",
    "                scores_10pct = pd.concat([scores_10pct, df], axis = 0)\n",
    "                counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "234a54df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write csv\n",
    "scores_10pct.to_csv(\"/home/lola/Nextcloud/Masterarbeit/03_Outputs/exp_scores_all_10pct_samples_it0.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a60347e",
   "metadata": {},
   "source": [
    "##### 25 pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b4f930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "flowCapF = [\"0.25\"]\n",
    "storCapF =  [\"0.25\", \"0.35355\"]\n",
    "stuckTimes = [\"30.0\", \"120.0\"]\n",
    "\n",
    "scores_25pct = pd.DataFrame()\n",
    "counter = 0\n",
    "for fCf in flowCapF:\n",
    "    for sCf in storCapF:\n",
    "        for sT in stuckTimes:\n",
    "            for sampleNr in range(1,2,1):\n",
    "                # declare path based on case \n",
    "                if((fCf == \"0.25\") & (sCf == \"0.25\") & (sT == \"30.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-25.0-pct-fCf_sCF_0.25_gS_4711_3765/ITERS/it.0/lausitz-25.0-pct-fCf_sCF_0.25_gS_4711_3765.0.experienced_plans.xml.gz\"       \n",
    "                elif((fCf == \"0.25\") & (sCf ==  \"0.35355\") & (sT == \"30.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-25.0-pct-fCf_0.25_sCF_0.35355_gS_4711_3765/ITERS/it.0/lausitz-25.0-pct-fCf_0.25_sCF_0.35355_gS_4711_3765.0.experienced_plans.xml.gz\"\n",
    "                elif((fCf == \"0.25\") & (sCf == \"0.25\") & (sT == \"120.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-25-pct-1-fCf_sCF_0.25_gS_4711_sT_120.0_3765/ITERS/it.0/lausitz-25-pct-1-fCf_sCF_0.25_gS_4711_sT_120.0_3765.0.experienced_plans.xml.gz\"\n",
    "                elif((fCf == \"0.25\") & (sCf ==  \"0.35355\") & (sT == \"120.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-25-pct-1-fCf_0.25_sCF_0.35355_gS_4711_sT_120.0_3765/ITERS/it.0/lausitz-25-pct-1-fCf_0.25_sCF_0.35355_gS_4711_sT_120.0_3765.0.experienced_plans.xml.gz\"  \n",
    "                else: \n",
    "                    print(\"case not found\")\n",
    "                    break\n",
    "                # read experienced plans file\n",
    "                plans = matsim.plan_reader(path, selected_plans_only = True)\n",
    "                # create list to store scores in\n",
    "                experienced_scores = []\n",
    "                # store all executed scores from plans file in list\n",
    "                for person, plan in plans:\n",
    "                    experienced_scores.append(plan.attrib['score'])\n",
    "                experienced_scores = pd.DataFrame({'exp_score': pd.to_numeric(experienced_scores)})\n",
    "                # calculate average of these scores\n",
    "                average = np.mean(experienced_scores['exp_score'])\n",
    "                if (sCf == \"0.35355\"): \n",
    "                    alpha = 0.75\n",
    "                elif(sCf == \"0.25\"):\n",
    "                    alpha = 1.0\n",
    "                # create df for specific case and store it in scores_25pct\n",
    "                df = pd.DataFrame({\"avg_executed_it_0\": average, \"sample_size\": \"25-pct\", \"sample_nr\": sampleNr, \"alpha\": alpha, \"stuck_time\": float(sT), \"global_seed\": \"default\" }, index = [counter])\n",
    "                scores_25pct = pd.concat([scores_25pct, df], axis = 0)\n",
    "                counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6df38267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write csv\n",
    "scores_25pct.to_csv(\"/home/lola/Nextcloud/Masterarbeit/03_Outputs/exp_scores_all_25pct_samples_it0.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037d95a5",
   "metadata": {},
   "source": [
    "##### 50 pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a39cc7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "flowCapF = [\"0.5\"]\n",
    "storCapF =  [\"0.5\", \"0.5946\"]\n",
    "stuckTimes = [\"30.0\", \"60.0\"]\n",
    "\n",
    "scores_50pct = pd.DataFrame()\n",
    "counter = 0\n",
    "for fCf in flowCapF:\n",
    "    for sCf in storCapF:\n",
    "        for sT in stuckTimes:\n",
    "            for sampleNr in range(1,2,1):\n",
    "                # declare path based on case \n",
    "                if((fCf == \"0.5\") & (sCf == \"0.5\") & (sT == \"30.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-50.0-pct-fCf_sCF_0.5_gS_4711_3765/ITERS/it.0/lausitz-50.0-pct-fCf_sCF_0.5_gS_4711_3765.0.experienced_plans.xml.gz\"       \n",
    "                elif((fCf == \"0.5\") & (sCf ==  \"0.5946\") & (sT == \"30.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-50.0-pct-fCf_0.5_sCF_0.5946_gS_4711_3765/ITERS/it.0/lausitz-50.0-pct-fCf_0.5_sCF_0.5946_gS_4711_3765.0.experienced_plans.xml.gz\"\n",
    "                elif((fCf == \"0.5\") & (sCf == \"0.5\") & (sT == \"60.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-50-pct-1-fCf_sCF_0.5_gS_4711_sT_60.0_3765/ITERS/it.0/lausitz-50-pct-1-fCf_sCF_0.5_gS_4711_sT_60.0_3765.0.experienced_plans.xml.gz\"\n",
    "                elif((fCf == \"0.5\") & (sCf ==  \"0.5946\") & (sT == \"60.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-50-pct-1-fCf_0.5_sCF_0.5946_gS_4711_sT_60.0_3765/ITERS/it.0/lausitz-50-pct-1-fCf_0.5_sCF_0.5946_gS_4711_sT_60.0_3765.0.experienced_plans.xml.gz\"  \n",
    "                else: \n",
    "                    print(\"case not found\")\n",
    "                    break\n",
    "                # read experienced plans file\n",
    "                plans = matsim.plan_reader(path, selected_plans_only = True)\n",
    "                # create list to store scores in\n",
    "                experienced_scores = []\n",
    "                # store all executed scores from plans file in list\n",
    "                for person, plan in plans:\n",
    "                    experienced_scores.append(plan.attrib['score'])\n",
    "                experienced_scores = pd.DataFrame({'exp_score': pd.to_numeric(experienced_scores)})\n",
    "                # calculate average of these scores\n",
    "                average = np.mean(experienced_scores['exp_score'])\n",
    "                if (sCf == \"0.5946\"): \n",
    "                    alpha = 0.75\n",
    "                elif( sCf == \"0.1\"):\n",
    "                    alpha = 1.0\n",
    "                # create df for specific case and store it in scores_10pct\n",
    "                df = pd.DataFrame({\"avg_executed_it_0\": average, \"sample_size\": \"50-pct\", \"sample_nr\": sampleNr, \"alpha\": alpha, \"stuck_time\": float(sT), \"global_seed\": \"default\" }, index = [counter])\n",
    "                scores_50pct = pd.concat([scores_50pct, df], axis = 0)\n",
    "                counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae797544",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/lola/Nextcloud/Masterarbeit/03_Outputs_From_RunsLausitz/output-lausitz-25-pct-doubled-fCf_0.5_sCF_0.5_gS_4711_3765/ITERS/it.0/lausitz-25-pct-doubled-fCf_0.5_sCF_0.5_gS_4711__3765.0.experienced_plans.xml.gz\"\n",
    "plans = matsim.plan_reader(path, selected_plans_only = True)\n",
    "                # create list to store scores in\n",
    "experienced_scores = []\n",
    "                # store all executed scores from plans file in list\n",
    "for person, plan in plans:\n",
    "    experienced_scores.append(plan.attrib['score'])\n",
    "experienced_scores = pd.DataFrame({'exp_score': pd.to_numeric(experienced_scores)})\n",
    "# calculate average of these scores\n",
    "average = np.mean(experienced_scores['exp_score'])\n",
    "# create df for specific case and store it in scores_10pct\n",
    "df = pd.DataFrame({\"avg_executed_it_0\": average, \"sample_size\": \"25-pct-doubled\", \"sample_nr\": 1, \"alpha\": 1.0, \"stuck_time\": 30.0, \"global_seed\": \"default\" }, index = [counter])\n",
    "scores_50pct = pd.concat([scores_50pct, df], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03f76008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write csv \n",
    "scores_50pct.to_csv(\"/home/lola/Nextcloud/Masterarbeit/03_Outputs/exp_scores_all_50pct_samples_it0.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de41f347",
   "metadata": {},
   "source": [
    "##### 100 pct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71b7eb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "flowCapF = [\"1.0\"]\n",
    "storCapF =  [\"1.0\"]\n",
    "stuckTimes = [\"30.0\"]\n",
    "\n",
    "scores_100pct = pd.DataFrame()\n",
    "counter = 0\n",
    "for fCf in flowCapF:\n",
    "    for sCf in storCapF:\n",
    "        for sT in stuckTimes:\n",
    "            for sampleNr in range(1,2,1):\n",
    "                # declare path based on case \n",
    "                path = \"/home/lola/math_cluster/output/output-lausitz-100.0-pct-fCf_sCF_1.0_gS_4711_3765/ITERS/it.0/lausitz-100.0-pct-fCf_sCF_1.0_gS_4711_3765.0.experienced_plans.xml.gz\"\n",
    "                # read experienced plans file\n",
    "                plans = matsim.plan_reader(path, selected_plans_only = True)\n",
    "                # create list to store scores in\n",
    "                experienced_scores = []\n",
    "                # store all executed scores from plans file in list\n",
    "                for person, plan in plans:\n",
    "                    experienced_scores.append(plan.attrib['score'])\n",
    "                experienced_scores = pd.DataFrame({'exp_score': pd.to_numeric(experienced_scores)})\n",
    "                # calculate average of these scores\n",
    "                average = np.mean(experienced_scores['exp_score'])\n",
    "                alpha = 1.0\n",
    "                # create df for specific case and store it in scores_10pct\n",
    "                df = pd.DataFrame({\"avg_executed_it_0\": average, \"sample_size\": \"100-pct\", \"sample_nr\": sampleNr, \"alpha\": alpha, \"stuck_time\": float(sT), \"global_seed\": \"default\" }, index = [counter])\n",
    "                scores_100pct = pd.concat([scores_100pct, df], axis = 0)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "646b604a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/lola/Nextcloud/Masterarbeit/03_Outputs_From_RunsLausitz/output-lausitz-25.0-pct-quadrupled-fCf_1.0_sCF_1.0_gS_4711_3765/ITERS/it.0/lausitz-25-pct-quadrupled-fCf_1.0_sCF_1.0_gS_4711__3765.0.experienced_plans.xml.gz\"\n",
    "plans = matsim.plan_reader(path, selected_plans_only = True)\n",
    "                # create list to store scores in\n",
    "experienced_scores = []\n",
    "                # store all executed scores from plans file in list\n",
    "for person, plan in plans:\n",
    "    experienced_scores.append(plan.attrib['score'])\n",
    "experienced_scores = pd.DataFrame({'exp_score': pd.to_numeric(experienced_scores)})\n",
    "# calculate average of these scores\n",
    "average = np.mean(experienced_scores['exp_score'])\n",
    "# create df for specific case and store it in scores_10pct\n",
    "df = pd.DataFrame({\"avg_executed_it_0\": average, \"sample_size\": \"25-pct-quadrupled\", \"sample_nr\": 1, \"alpha\": 1.0, \"stuck_time\": 30.0, \"global_seed\": \"default\" }, index = [counter])\n",
    "scores_100pct = pd.concat([scores_100pct, df], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcdb1f9",
   "metadata": {},
   "source": [
    "##### Concat and write output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "962776c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat all\n",
    "scores_1_100 = pd.concat([scores_1pct_all_it0, scores_5pct_all_it0, scores_10pct, scores_25pct, scores_50pct, scores_100pct ], axis = 0)\n",
    "# write all to csv\n",
    "scores_1_100.to_csv(\"/home/lola/Nextcloud/Masterarbeit/03_Outputs/exp_scores_all_1_100pct_samples_it0.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6173cd1",
   "metadata": {},
   "source": [
    "#### Average Traveltime and distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3503ae52",
   "metadata": {},
   "source": [
    "##### 1 pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "475469fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### average travel time and average traveled distance ####\n",
    "# trav_time and traveled_distance\n",
    "# 1 pct, alpha = 1\n",
    "flowCapF = [\"0.01\"]\n",
    "storCapF = [\"0.01\", \"0.03162\"]\n",
    "stuckTimes = [\"30.0\", \"3000.0\"]\n",
    "\n",
    "avg_trav_time_1pct = pd.DataFrame()\n",
    "avg_trav_dist_1pct = pd.DataFrame()\n",
    "for fCf in flowCapF:\n",
    "    for sCf in storCapF:\n",
    "        for sT in stuckTimes:\n",
    "            for sampleNr in range(1,11,1):\n",
    "                if((fCf == \"0.01\") & (sCf == \"0.01\") & (sT == \"30.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-1pct-\" + str(sampleNr) + \"-fCf_sCF_\" + fCf + \"_gS_default_3765/ITERS/it.0/lausitz-1pct-\" + str(sampleNr) + \"-fCf_sCf_\" + fCf + \"_gS_default_3765.0.trips.csv.gz\"   \n",
    "                elif((fCf == \"0.01\") & (sCf ==  \"0.03162\") & (sT == \"30.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-1pct-\"+ str(sampleNr) +  \"-fCf_0.01_sCF_\" + sCf + \"_gS_default_3765/ITERS/it.0/lausitz-1pct-\" +str(sampleNr) + \"-fCf_0.01_sCf_\" + sCf + \"_gS_default_3765.0.trips.csv.gz\"\n",
    "                elif((fCf == \"0.01\") & (sCf == \"0.01\") & (sT == \"3000.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-1-pct-\" + str(sampleNr) +\"-fCf_sCF_\" + fCf + \"_gS_4711_sT_3000.0_3765/ITERS/it.0/lausitz-1-pct-\" + str(sampleNr) + \"-fCf_sCF_\"+ fCf + \"_gS_4711_sT_3000.0_3765.0.trips.csv.gz\"\n",
    "                elif((fCf == \"0.01\") & (sCf ==  \"0.03162\") & (sT == \"3000.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-1-pct-\" + str(sampleNr) + \"-fCf_0.01_sCF_0.03162_gS_4711_sT_3000.0_3765/ITERS/it.0/lausitz-1-pct-\" + str(sampleNr) + \"-fCf_0.01_sCF_0.03162_gS_4711_sT_3000.0_3765.0.trips.csv.gz\"  \n",
    "                else: \n",
    "                    print(\"case not found\")\n",
    "                    break\n",
    "                temp = pd.read_csv(path, compression= \"gzip\", sep=\";\")\n",
    "                temp[\"trav_time\"] = pd.to_timedelta(temp.trav_time)\n",
    "                avg_trav_time = temp[\"trav_time\"].sum() / temp[\"trav_time\"].shape[0]\n",
    "                if(sCf == \"0.03162\"):\n",
    "                    alpha = 0.75\n",
    "                else: \n",
    "                    alpha = 1.0\n",
    "\n",
    "                df_avg_trav_time = pd.DataFrame({\"avg_trav_time\": avg_trav_time, \"sample_size\": \"1-pct\", \"sample_nr\": sampleNr, \"alpha\" : alpha, \"stuck_time\": float(sT), \"global_seed\": \"default\"}, index=[sampleNr])\n",
    "                avg_trav_time_1pct = pd.concat([avg_trav_time_1pct, df_avg_trav_time], axis = 0)\n",
    "\n",
    "                avg_trav_dist = np.mean(temp[\"traveled_distance\"])\n",
    "                df_avg_trav_dist = pd.DataFrame({\"avg_trav_dist\": avg_trav_dist, \"sample_size\": \"1-pct\", \"sample_nr\": sampleNr, \"alpha\" : alpha, \"stuck_time\": float(sT), \"global_seed\": \"default\"}, index=[sampleNr])\n",
    "                avg_trav_dist_1pct = pd.concat([avg_trav_dist_1pct, df_avg_trav_dist], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "caa3635b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 pct rGs\n",
    "avg_trav_time_1pct_rGs = pd.DataFrame()\n",
    "avg_trav_dist_1pct_rGs = pd.DataFrame()\n",
    "rGs = [ 4711,3254, 2306, 6384,4338, 6003, 5502, 9377, 5621, 9002 ]\n",
    "for seed in rGs:\n",
    "    if (seed == 4711):\n",
    "        global_seed = \"rnd_\" + str(seed)\n",
    "        # Create Data frame and insert first value from avg_trav_time_1pct\n",
    "        df1 = pd.DataFrame({\"avg_trav_time\":avg_trav_time_1pct[\"avg_trav_time\"].iloc[0], \"sample_size\": \"1-pct\", \"sample_nr\": 1, \"alpha\": 1.0, \"stuck_time\": 30.0, \"global_seed\": global_seed }, index = [rGs.index(seed)])\n",
    "        avg_trav_time_1pct_rGs = pd.concat([avg_trav_time_1pct_rGs, df1])\n",
    "        \n",
    "        # Create Data frame and insert first value from avg_trav_dist_1pct\n",
    "        df1 = pd.DataFrame({\"avg_trav_dist\":avg_trav_dist_1pct[\"avg_trav_dist\"].iloc[0], \"sample_size\": \"1-pct\", \"sample_nr\": 1, \"alpha\": 1.0, \"stuck_time\": 30.0, \"global_seed\": global_seed }, index = [rGs.index(seed)])\n",
    "        avg_trav_dist_1pct_rGs = pd.concat([avg_trav_dist_1pct_rGs, df1])\n",
    "\n",
    "    elif (seed == 3254):\n",
    "        global_seed = \"rnd_\" + str(seed)\n",
    "        path =\"/home/lola/math_cluster/output/output-lausitz-1pct-1-fCf_sCF_0.01_gS_3254_3765/ITERS/it.0/lausitz-1pct-1-fCf_sCf_0.01_gS_3254_3765.0.trips.csv.gz\"\n",
    "        temp = pd.read_csv(path, compression= \"gzip\", sep=\";\")\n",
    "        temp[\"trav_time\"] = pd.to_timedelta(temp.trav_time)\n",
    "        avg_trav_time =  temp[\"trav_time\"].sum() / temp[\"trav_time\"].shape[0]\n",
    "        # average travel time\n",
    "        df1 = pd.DataFrame({\"avg_trav_time\":avg_trav_time, \"sample_size\": \"1-pct\", \"sample_nr\": 1, \"alpha\":1.0, \"stuck_time\": 30.0, \"global_seed\": global_seed }, index = [rGs.index(seed)])\n",
    "        avg_trav_time_1pct_rGs = pd.concat([avg_trav_time_1pct_rGs, df1], axis = 0)\n",
    "        # average traveled distance\n",
    "        avg_trav_dist = np.mean(temp[\"traveled_distance\"])\n",
    "        df_avg_trav_dist = pd.DataFrame({\"avg_trav_dist\": avg_trav_dist, \"sample_size\": \"1-pct\", \"sample_nr\": 1, \"alpha\" : 1.0, \"stuck_time\": 30.0, \"global_seed\": global_seed}, index=[rGs.index(seed)])\n",
    "        avg_trav_dist_1pct_rGs = pd.concat([avg_trav_dist_1pct_rGs, df_avg_trav_dist], axis = 0)\n",
    "\n",
    "    else:\n",
    "        global_seed = \"rnd_\" + str(seed)\n",
    "        path =\"/home/lola/math_cluster/output/output-lausitz-1.0-pct-1-fCf_sCF_0.01_gS_\" + str(seed) + \"_3765/ITERS/it.0/lausitz-1.0-pct-1-fCf_sCF_0.01_gS_\" + str(seed) + \"_3765.0.trips.csv.gz\"\n",
    "        temp = pd.read_csv(path, compression= \"gzip\", sep=\";\")\n",
    "        temp[\"trav_time\"] = pd.to_timedelta(temp.trav_time)\n",
    "        avg_trav_time =  temp[\"trav_time\"].sum() / temp[\"trav_time\"].shape[0]\n",
    "        # average travel time\n",
    "        df1 = pd.DataFrame({\"avg_trav_time\":avg_trav_time, \"sample_size\": \"1-pct\", \"sample_nr\": 1, \"alpha\":1.0, \"stuck_time\": 30.0, \"global_seed\": global_seed }, index = [rGs.index(seed)])\n",
    "        avg_trav_time_1pct_rGs = pd.concat([avg_trav_time_1pct_rGs, df1], axis = 0)\n",
    "        # average traveled distance\n",
    "        avg_trav_dist = np.mean(temp[\"traveled_distance\"])\n",
    "        df_avg_trav_dist = pd.DataFrame({\"avg_trav_dist\": avg_trav_dist, \"sample_size\": \"1-pct\", \"sample_nr\": 1, \"alpha\" : 1.0, \"stuck_time\": 30.0, \"global_seed\": global_seed}, index=[rGs.index(seed)])\n",
    "        avg_trav_dist_1pct_rGs = pd.concat([avg_trav_dist_1pct_rGs, df_avg_trav_dist], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f17ada41",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_trav_time_1pct_all = pd.concat([avg_trav_time_1pct, avg_trav_time_1pct_rGs], axis = 0 , ignore_index= True)\n",
    "avg_trav_time_1pct_all.to_csv('/home/lola/Nextcloud/Masterarbeit/03_Outputs/avg_trav_time_all_1pct_samples_it0.csv', index = False) \n",
    "avg_trav_dist_1pct_all = pd.concat([avg_trav_dist_1pct, avg_trav_dist_1pct_rGs ], axis = 0 , ignore_index= True)\n",
    "avg_trav_dist_1pct_all.to_csv('/home/lola/Nextcloud/Masterarbeit/03_Outputs/avg_trav_dist_all_1pct_samples_it0.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9503b820",
   "metadata": {},
   "source": [
    "##### 5pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "62c9b534",
   "metadata": {},
   "outputs": [],
   "source": [
    "flowCapF = [\"0.05\"]\n",
    "storCapF =  [\"0.05\", \"0.10574\"]\n",
    "stuckTimes = [\"30.0\", \"600.0\"]\n",
    "\n",
    "avg_trav_time_5pct = pd.DataFrame()\n",
    "avg_trav_dist_5pct = pd.DataFrame()\n",
    "\n",
    "for fCf in flowCapF:\n",
    "    for sCf in storCapF:\n",
    "        for sT in stuckTimes:\n",
    "            for sampleNr in range(1,11,1):\n",
    "                # declare path based on case \n",
    "                if((fCf == \"0.05\") & (sCf == \"0.05\") & (sT == \"30.0\")):\n",
    "                    if (sampleNr == 6):\n",
    "                        path  = \"/home/lola/math_cluster/output/output-lausitz-5.0-pct-6-fCf_sCF_0.05_gS_4711_3765/ITERS/it.0/lausitz-5.0-pct-6-fCf_sCF_0.05_gS_4711_3765-2.0.trips.csv.gz\"\n",
    "                    else: \n",
    "                        path = \"/home/lola/math_cluster/output/output-lausitz-5.0-pct-\" + str(sampleNr) + \"-fCf_sCF_0.05_gS_4711_3765/ITERS/it.0/lausitz-5.0-pct-\" + str(sampleNr) + \"-fCf_sCF_0.05_gS_4711_3765.0.trips.csv.gz\"\n",
    "                    \n",
    "                elif((fCf == \"0.05\") & (sCf ==  \"0.10574\") & (sT == \"30.0\")):\n",
    "                    if(sampleNr == 6):\n",
    "                        path = \"/home/lola/math_cluster/output/output-lausitz-5.0-pct-6-fCf_0.05_sCF_0.10574_gS_4711_3765/ITERS/it.0/lausitz-5.0-pct-6-fCf_0.05_sCF_0.10574_gS_4711_3765-2.0.trips.csv.gz\"\n",
    "                    else:\n",
    "                        path = \"/home/lola/math_cluster/output/output-lausitz-5.0-pct-\" + str(sampleNr) + \"-fCf_0.05_sCF_0.10574_gS_4711_3765/ITERS/it.0/lausitz-5.0-pct-\" + str(sampleNr) + \"-fCf_0.05_sCF_0.10574_gS_4711_3765.0.trips.csv.gz\"\n",
    "                elif((fCf == \"0.05\") & (sCf == \"0.05\") & (sT == \"600.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-5-pct-\" + str(sampleNr) + \"-fCf_sCF_0.05_gS_4711_sT_600.0_3765/ITERS/it.0/lausitz-5-pct-\" + str(sampleNr) + \"-fCf_sCF_0.05_gS_4711_sT_600.0_3765.0.trips.csv.gz\"\n",
    "                elif((fCf == \"0.05\") & (sCf ==  \"0.10574\") & (sT == \"600.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-5-pct-\" + str(sampleNr) + \"-fCf_0.05_sCF_0.10574_gS_4711_sT_600.0_3765/ITERS/it.0/lausitz-5-pct-\" + str(sampleNr) + \"-fCf_0.05_sCF_0.10574_gS_4711_sT_600.0_3765.0.trips.csv.gz\"\n",
    "                \n",
    "                else: \n",
    "                    print(\"case not found\")\n",
    "                    break\n",
    "                # calculate average travel time\n",
    "                temp = pd.read_csv(path, compression= \"gzip\", sep=\";\")\n",
    "                temp[\"trav_time\"] = pd.to_timedelta(temp.trav_time)\n",
    "                avg_trav_time = temp[\"trav_time\"].sum() / temp[\"trav_time\"].shape[0]\n",
    "                if(sCf == \"0.10574\"):\n",
    "                    alpha = 0.75\n",
    "                else: \n",
    "                    alpha = 1.0\n",
    "\n",
    "                df_avg_trav_time = pd.DataFrame({\"avg_trav_time\": avg_trav_time, \"sample_size\": \"5-pct\", \"sample_nr\": sampleNr, \"alpha\" : alpha, \"stuck_time\": float(sT), \"global_seed\": \"default\"}, index=[sampleNr])\n",
    "                avg_trav_time_5pct = pd.concat([avg_trav_time_5pct, df_avg_trav_time], axis = 0)\n",
    "                # calculate average traveled distance\n",
    "                avg_trav_dist = np.mean(temp[\"traveled_distance\"])\n",
    "                df_avg_trav_dist = pd.DataFrame({\"avg_trav_dist\": avg_trav_dist, \"sample_size\": \"5-pct\", \"sample_nr\": sampleNr, \"alpha\" : alpha, \"stuck_time\": float(sT), \"global_seed\": \"default\"}, index=[sampleNr])\n",
    "                avg_trav_dist_5pct = pd.concat([avg_trav_dist_5pct, df_avg_trav_dist], axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ec9505c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 pct random global seed\n",
    "avg_trav_time_5pct_rGs = pd.DataFrame()\n",
    "avg_trav_dist_5pct_rGs = pd.DataFrame()\n",
    "rGs = [ 4711,3254, 2306, 6384,4338, 6003, 5502, 9377, 5621, 9002 ]\n",
    "for seed in rGs:\n",
    "    if (seed == 4711):\n",
    "        global_seed = \"rnd_\" + str(seed)\n",
    "        # Create Data frame and insert first value from avg_trav_time_5pct\n",
    "        df1 = pd.DataFrame({\"avg_trav_time\":avg_trav_time_5pct[\"avg_trav_time\"].iloc[0], \"sample_size\": \"5-pct\", \"sample_nr\": 1, \"alpha\": 1.0, \"stuck_time\": 30.0, \"global_seed\": global_seed }, index = [rGs.index(seed)])\n",
    "        avg_trav_time_5pct_rGs = pd.concat([avg_trav_time_5pct_rGs, df1])\n",
    "        \n",
    "        # Create Data frame and insert first value from avg_trav_dist_5pct\n",
    "        df1 = pd.DataFrame({\"avg_trav_dist\":avg_trav_dist_5pct[\"avg_trav_dist\"].iloc[0], \"sample_size\": \"5-pct\", \"sample_nr\": 1, \"alpha\": 1.0, \"stuck_time\": 30.0, \"global_seed\": global_seed }, index = [rGs.index(seed)])\n",
    "        avg_trav_dist_5pct_rGs = pd.concat([avg_trav_dist_5pct_rGs, df1])\n",
    "\n",
    "    elif (seed == 3254):\n",
    "        global_seed = \"rnd_\" + str(seed)\n",
    "        path =\"/home/lola/math_cluster/output/output-lausitz-5.0-pct-1-fCf_sCF_0.05_gS_3254_3765/ITERS/it.0/lausitz-5.0-pct-1-fCf_sCF_0.05_gS_3254_3765.0.trips.csv.gz\"\n",
    "        temp = pd.read_csv(path, compression= \"gzip\", sep=\";\")\n",
    "        temp[\"trav_time\"] = pd.to_timedelta(temp.trav_time)\n",
    "        avg_trav_time =  temp[\"trav_time\"].sum() / temp[\"trav_time\"].shape[0]\n",
    "        # average travel time\n",
    "        df1 = pd.DataFrame({\"avg_trav_time\":avg_trav_time, \"sample_size\": \"5-pct\", \"sample_nr\": 1, \"alpha\":1.0, \"stuck_time\": 30.0, \"global_seed\": global_seed }, index = [rGs.index(seed)])\n",
    "        avg_trav_time_5pct_rGs = pd.concat([avg_trav_time_5pct_rGs, df1], axis = 0)\n",
    "        # average traveled distance\n",
    "        avg_trav_dist = np.mean(temp[\"traveled_distance\"])\n",
    "        df_avg_trav_dist = pd.DataFrame({\"avg_trav_dist\": avg_trav_dist, \"sample_size\": \"5-pct\", \"sample_nr\": 1, \"alpha\" : 1.0, \"stuck_time\": 30.0, \"global_seed\": global_seed}, index=[rGs.index(seed)])\n",
    "        avg_trav_dist_5pct_rGs = pd.concat([avg_trav_dist_5pct_rGs, df_avg_trav_dist], axis = 0)\n",
    "\n",
    "    else:\n",
    "        global_seed = \"rnd_\" + str(seed)\n",
    "        path =\"/home/lola/math_cluster/output/output-lausitz-5.0-pct-1-fCf_sCF_0.05_gS_\" + str(seed) + \"_3765/ITERS/it.0/lausitz-5.0-pct-1-fCf_sCF_0.05_gS_\" + str(seed) + \"_3765.0.trips.csv.gz\"\n",
    "        temp = pd.read_csv(path, compression= \"gzip\", sep=\";\")\n",
    "        temp[\"trav_time\"] = pd.to_timedelta(temp.trav_time)\n",
    "        avg_trav_time =  temp[\"trav_time\"].sum() / temp[\"trav_time\"].shape[0]\n",
    "        # average travel time\n",
    "        df1 = pd.DataFrame({\"avg_trav_time\":avg_trav_time, \"sample_size\": \"5-pct\", \"sample_nr\": 1, \"alpha\":1.0, \"stuck_time\": 30.0, \"global_seed\": global_seed }, index = [rGs.index(seed)])\n",
    "        avg_trav_time_5pct_rGs = pd.concat([avg_trav_time_5pct_rGs, df1], axis = 0)\n",
    "        # average traveled distance\n",
    "        avg_trav_dist = np.mean(temp[\"traveled_distance\"])\n",
    "        df_avg_trav_dist = pd.DataFrame({\"avg_trav_dist\": avg_trav_dist, \"sample_size\": \"5-pct\", \"sample_nr\": 1, \"alpha\" : 1.0, \"stuck_time\": 30.0, \"global_seed\": global_seed}, index=[rGs.index(seed)])\n",
    "        avg_trav_dist_5pct_rGs = pd.concat([avg_trav_dist_5pct_rGs, df_avg_trav_dist], axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5f7b3c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_trav_time_5pct_all = pd.concat([avg_trav_time_5pct, avg_trav_time_5pct_rGs], axis = 0 , ignore_index= True)\n",
    "avg_trav_time_5pct_all.to_csv('/home/lola/Nextcloud/Masterarbeit/03_Outputs/avg_trav_time_all_5pct_samples_it0.csv', index = False) \n",
    "avg_trav_dist_5pct_all = pd.concat([avg_trav_dist_5pct, avg_trav_dist_5pct_rGs ], axis = 0 , ignore_index= True)\n",
    "avg_trav_dist_5pct_all.to_csv('/home/lola/Nextcloud/Masterarbeit/03_Outputs/avg_trav_dist_all_5pct_samples_it0.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d25841",
   "metadata": {},
   "source": [
    "##### 10 pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d9c01a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5897/1327652803.py:24: DtypeWarning: Columns (21,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp = pd.read_csv(path, compression= \"gzip\", sep=\";\")\n",
      "/tmp/ipykernel_5897/1327652803.py:24: DtypeWarning: Columns (21,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp = pd.read_csv(path, compression= \"gzip\", sep=\";\")\n",
      "/tmp/ipykernel_5897/1327652803.py:24: DtypeWarning: Columns (21,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp = pd.read_csv(path, compression= \"gzip\", sep=\";\")\n",
      "/tmp/ipykernel_5897/1327652803.py:24: DtypeWarning: Columns (21,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp = pd.read_csv(path, compression= \"gzip\", sep=\";\")\n",
      "/tmp/ipykernel_5897/1327652803.py:24: DtypeWarning: Columns (21,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp = pd.read_csv(path, compression= \"gzip\", sep=\";\")\n",
      "/tmp/ipykernel_5897/1327652803.py:24: DtypeWarning: Columns (21,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp = pd.read_csv(path, compression= \"gzip\", sep=\";\")\n",
      "/tmp/ipykernel_5897/1327652803.py:24: DtypeWarning: Columns (21,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp = pd.read_csv(path, compression= \"gzip\", sep=\";\")\n",
      "/tmp/ipykernel_5897/1327652803.py:24: DtypeWarning: Columns (21,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp = pd.read_csv(path, compression= \"gzip\", sep=\";\")\n",
      "/tmp/ipykernel_5897/1327652803.py:24: DtypeWarning: Columns (21,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp = pd.read_csv(path, compression= \"gzip\", sep=\";\")\n",
      "/tmp/ipykernel_5897/1327652803.py:24: DtypeWarning: Columns (21,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp = pd.read_csv(path, compression= \"gzip\", sep=\";\")\n",
      "/tmp/ipykernel_5897/1327652803.py:24: DtypeWarning: Columns (21,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp = pd.read_csv(path, compression= \"gzip\", sep=\";\")\n",
      "/tmp/ipykernel_5897/1327652803.py:24: DtypeWarning: Columns (21,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp = pd.read_csv(path, compression= \"gzip\", sep=\";\")\n"
     ]
    }
   ],
   "source": [
    "flowCapF = [\"0.1\"]\n",
    "storCapF =  [\"0.1\", \"0.17783\"]\n",
    "stuckTimes = [\"30.0\", \"300.0\"]\n",
    "\n",
    "avg_trav_time_10pct = pd.DataFrame()\n",
    "avg_trav_dist_10pct = pd.DataFrame()\n",
    "counter = 0\n",
    "for fCf in flowCapF:\n",
    "    for sCf in storCapF:\n",
    "        for sT in stuckTimes:\n",
    "            for sampleNr in range(1,11,1):\n",
    "                # declare path based on case \n",
    "                if((fCf == \"0.1\") & (sCf == \"0.1\") & (sT == \"30.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-10.0-pct-\" +str(sampleNr) + \"-fCf_sCF_0.1_gS_4711_3765/ITERS/it.0/lausitz-10.0-pct-\" + str(sampleNr) +\"-fCf_sCF_0.1_gS_4711_3765.0.trips.csv.gz\"       \n",
    "                elif((fCf == \"0.1\") & (sCf ==  \"0.17783\") & (sT == \"30.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-10.0-pct-\" + str(sampleNr) + \"-fCf_0.1_sCF_0.17783_gS_4711_3765/ITERS/it.0/lausitz-10.0-pct-\" + str(sampleNr) + \"-fCf_0.1_sCF_0.17783_gS_4711_3765.0.trips.csv.gz\"\n",
    "                elif((fCf == \"0.1\") & (sCf == \"0.1\") & (sT == \"300.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-10-pct-\" + str(sampleNr) + \"-fCf_sCF_0.1_gS_4711_sT_300.0_3765/ITERS/it.0/lausitz-10-pct-\" + str(sampleNr) + \"-fCf_sCF_0.1_gS_4711_sT_300.0_3765.0.trips.csv.gz\"\n",
    "                elif((fCf == \"0.1\") & (sCf ==  \"0.17783\") & (sT == \"300.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-10-pct-\" + str(sampleNr) + \"-fCf_0.1_sCF_0.17783_gS_4711_sT_300.0_3765/ITERS/it.0/lausitz-10-pct-\" + str(sampleNr) + \"-fCf_0.1_sCF_0.17783_gS_4711_sT_300.0_3765.0.trips.csv.gz\"  \n",
    "                else: \n",
    "                    print(\"case not found\")\n",
    "                    break\n",
    "                temp = pd.read_csv(path, compression= \"gzip\", sep=\";\")\n",
    "                temp[\"trav_time\"] = pd.to_timedelta(temp.trav_time)\n",
    "                avg_trav_time = temp[\"trav_time\"].sum() / temp[\"trav_time\"].shape[0]\n",
    "                if(sCf == \"0.17783\"):\n",
    "                    alpha = 0.75\n",
    "                else: \n",
    "                    alpha = 1.0\n",
    "\n",
    "                df_avg_trav_time = pd.DataFrame({\"avg_trav_time\": avg_trav_time, \"sample_size\": \"10-pct\", \"sample_nr\": sampleNr, \"alpha\" : alpha, \"stuck_time\": float(sT), \"global_seed\": \"default\"}, index=[sampleNr])\n",
    "                avg_trav_time_10pct = pd.concat([avg_trav_time_10pct, df_avg_trav_time], axis = 0)\n",
    "                # calculate average traveled distance\n",
    "                avg_trav_dist = np.mean(temp[\"traveled_distance\"])\n",
    "                df_avg_trav_dist = pd.DataFrame({\"avg_trav_dist\": avg_trav_dist, \"sample_size\": \"10-pct\", \"sample_nr\": sampleNr, \"alpha\" : alpha, \"stuck_time\": float(sT), \"global_seed\": \"default\"}, index=[sampleNr])\n",
    "                avg_trav_dist_10pct = pd.concat([avg_trav_dist_10pct, df_avg_trav_dist], axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b72553c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_trav_time_10pct.to_csv('/home/lola/Nextcloud/Masterarbeit/03_Outputs/avg_trav_time_all_10pct_samples_it0.csv', index = False) \n",
    "avg_trav_dist_10pct.to_csv('/home/lola/Nextcloud/Masterarbeit/03_Outputs/avg_trav_dist_all_10pct_samples_it0.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925d60db",
   "metadata": {},
   "source": [
    "##### 25 pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "93c5a6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "flowCapF = [\"0.25\"]\n",
    "storCapF =  [\"0.25\", \"0.35355\"]\n",
    "stuckTimes = [\"30.0\", \"120.0\"]\n",
    "\n",
    "avg_trav_time_25pct = pd.DataFrame()\n",
    "avg_trav_dist_25pct = pd.DataFrame()\n",
    "counter = 0\n",
    "for fCf in flowCapF:\n",
    "    for sCf in storCapF:\n",
    "        for sT in stuckTimes:\n",
    "            for sampleNr in range(1,2,1):\n",
    "                # declare path based on case \n",
    "                if((fCf == \"0.25\") & (sCf == \"0.25\") & (sT == \"30.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-25.0-pct-fCf_sCF_0.25_gS_4711_3765/ITERS/it.0/lausitz-25.0-pct-fCf_sCF_0.25_gS_4711_3765.0.trips.csv.gz\"       \n",
    "                elif((fCf == \"0.25\") & (sCf ==  \"0.35355\") & (sT == \"30.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-25.0-pct-fCf_0.25_sCF_0.35355_gS_4711_3765/ITERS/it.0/lausitz-25.0-pct-fCf_0.25_sCF_0.35355_gS_4711_3765.0.trips.csv.gz\"\n",
    "                elif((fCf == \"0.25\") & (sCf == \"0.25\") & (sT == \"120.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-25-pct-1-fCf_sCF_0.25_gS_4711_sT_120.0_3765/ITERS/it.0/lausitz-25-pct-1-fCf_sCF_0.25_gS_4711_sT_120.0_3765.0.trips.csv.gz\"\n",
    "                elif((fCf == \"0.25\") & (sCf ==  \"0.35355\") & (sT == \"120.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-25-pct-1-fCf_0.25_sCF_0.35355_gS_4711_sT_120.0_3765/ITERS/it.0/lausitz-25-pct-1-fCf_0.25_sCF_0.35355_gS_4711_sT_120.0_3765.0.trips.csv.gz\"  \n",
    "                else: \n",
    "                    print(\"case not found\")\n",
    "                    break\n",
    "                temp = pd.read_csv(path, compression= \"gzip\", sep=\";\")\n",
    "                temp[\"trav_time\"] = pd.to_timedelta(temp.trav_time)\n",
    "                avg_trav_time = temp[\"trav_time\"].sum() / temp[\"trav_time\"].shape[0]\n",
    "                if(sCf == \"0.35355\"):\n",
    "                    alpha = 0.75\n",
    "                else: \n",
    "                    alpha = 1.0\n",
    "\n",
    "                df_avg_trav_time = pd.DataFrame({\"avg_trav_time\": avg_trav_time, \"sample_size\": \"25-pct\", \"sample_nr\": sampleNr, \"alpha\" : alpha, \"stuck_time\": float(sT), \"global_seed\": \"default\"}, index=[sampleNr])\n",
    "                avg_trav_time_25pct = pd.concat([avg_trav_time_25pct, df_avg_trav_time], axis = 0)\n",
    "                # calculate average traveled distance\n",
    "                avg_trav_dist = np.mean(temp[\"traveled_distance\"])\n",
    "                df_avg_trav_dist = pd.DataFrame({\"avg_trav_dist\": avg_trav_dist, \"sample_size\": \"25-pct\", \"sample_nr\": sampleNr, \"alpha\" : alpha, \"stuck_time\": float(sT), \"global_seed\": \"default\"}, index=[sampleNr])\n",
    "                avg_trav_dist_25pct = pd.concat([avg_trav_dist_25pct, df_avg_trav_dist], axis = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dac158e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_trav_time_25pct.to_csv('/home/lola/Nextcloud/Masterarbeit/03_Outputs/avg_trav_time_all_25pct_samples_it0.csv', index = False) \n",
    "avg_trav_dist_25pct.to_csv('/home/lola/Nextcloud/Masterarbeit/03_Outputs/avg_trav_dist_all_25pct_samples_it0.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01eaa9b7",
   "metadata": {},
   "source": [
    "##### 50 pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "12bacdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "flowCapF = [\"0.5\"]\n",
    "storCapF =  [\"0.5\", \"0.5946\"]\n",
    "stuckTimes = [\"30.0\", \"60.0\"]\n",
    "\n",
    "avg_trav_time_50pct = pd.DataFrame()\n",
    "avg_trav_dist_50pct = pd.DataFrame()\n",
    "counter = 0\n",
    "for fCf in flowCapF:\n",
    "    for sCf in storCapF:\n",
    "        for sT in stuckTimes:\n",
    "            for sampleNr in range(1,2,1):\n",
    "                # declare path based on case \n",
    "                if((fCf == \"0.5\") & (sCf == \"0.5\") & (sT == \"30.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-50.0-pct-fCf_sCF_0.5_gS_4711_3765/ITERS/it.0/lausitz-50.0-pct-fCf_sCF_0.5_gS_4711_3765.0.trips.csv.gz\"       \n",
    "                elif((fCf == \"0.5\") & (sCf ==  \"0.5946\") & (sT == \"30.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-50.0-pct-fCf_0.5_sCF_0.5946_gS_4711_3765/ITERS/it.0/lausitz-50.0-pct-fCf_0.5_sCF_0.5946_gS_4711_3765.0.trips.csv.gz\"\n",
    "                elif((fCf == \"0.5\") & (sCf == \"0.5\") & (sT == \"60.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-50-pct-1-fCf_sCF_0.5_gS_4711_sT_60.0_3765/ITERS/it.0/lausitz-50-pct-1-fCf_sCF_0.5_gS_4711_sT_60.0_3765.0.trips.csv.gz\"\n",
    "                elif((fCf == \"0.5\") & (sCf ==  \"0.5946\") & (sT == \"60.0\")):\n",
    "                    path = \"/home/lola/math_cluster/output/output-lausitz-50-pct-1-fCf_0.5_sCF_0.5946_gS_4711_sT_60.0_3765/ITERS/it.0/lausitz-50-pct-1-fCf_0.5_sCF_0.5946_gS_4711_sT_60.0_3765.0.trips.csv.gz\"  \n",
    "                else: \n",
    "                    print(\"case not found\")\n",
    "                    break\n",
    "                temp = pd.read_csv(path, compression= \"gzip\", sep=\";\")\n",
    "                temp[\"trav_time\"] = pd.to_timedelta(temp.trav_time)\n",
    "                avg_trav_time = temp[\"trav_time\"].sum() / temp[\"trav_time\"].shape[0]\n",
    "                if(sCf == \"0.5946\"):\n",
    "                    alpha = 0.75\n",
    "                else: \n",
    "                    alpha = 1.0\n",
    "\n",
    "                df_avg_trav_time = pd.DataFrame({\"avg_trav_time\": avg_trav_time, \"sample_size\": \"50-pct\", \"sample_nr\": sampleNr, \"alpha\" : alpha, \"stuck_time\": float(sT), \"global_seed\": \"default\"}, index=[sampleNr])\n",
    "                avg_trav_time_50pct = pd.concat([avg_trav_time_50pct, df_avg_trav_time], axis = 0)\n",
    "                # calculate average traveled distance\n",
    "                avg_trav_dist = np.mean(temp[\"traveled_distance\"])\n",
    "                df_avg_trav_dist = pd.DataFrame({\"avg_trav_dist\": avg_trav_dist, \"sample_size\": \"50-pct\", \"sample_nr\": sampleNr, \"alpha\" : alpha, \"stuck_time\": float(sT), \"global_seed\": \"default\"}, index=[sampleNr])\n",
    "                avg_trav_dist_50pct = pd.concat([avg_trav_dist_50pct, df_avg_trav_dist], axis = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9d243c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_trav_time_50pct.to_csv('/home/lola/Nextcloud/Masterarbeit/03_Outputs/avg_trav_time_all_50pct_samples_it0.csv', index = False) \n",
    "avg_trav_dist_50pct.to_csv('/home/lola/Nextcloud/Masterarbeit/03_Outputs/avg_trav_dist_all_50pct_samples_it0.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f0ee3c",
   "metadata": {},
   "source": [
    "##### 100 pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5266da44",
   "metadata": {},
   "outputs": [],
   "source": [
    "flowCapF = [\"1.0\"]\n",
    "storCapF =  [\"1.0\"]\n",
    "stuckTimes = [\"30.0\"]\n",
    "\n",
    "avg_trav_time_100pct = pd.DataFrame()\n",
    "avg_trav_dist_100pct = pd.DataFrame()\n",
    "counter = 0\n",
    "for fCf in flowCapF:\n",
    "    for sCf in storCapF:\n",
    "        for sT in stuckTimes:\n",
    "            for sampleNr in range(1,2,1):\n",
    "                # declare path based on case \n",
    "                path = \"/home/lola/math_cluster/output/output-lausitz-100.0-pct-fCf_sCF_1.0_gS_4711_3765/ITERS/it.0/lausitz-100.0-pct-fCf_sCF_1.0_gS_4711_3765.0.trips.csv.gz\"\n",
    "                temp = pd.read_csv(path, compression= \"gzip\", sep=\";\")\n",
    "                temp[\"trav_time\"] = pd.to_timedelta(temp.trav_time)\n",
    "                avg_trav_time = temp[\"trav_time\"].sum() / temp[\"trav_time\"].shape[0]\n",
    "                alpha = 1.0\n",
    "\n",
    "                df_avg_trav_time = pd.DataFrame({\"avg_trav_time\": avg_trav_time, \"sample_size\": \"100-pct\", \"sample_nr\": sampleNr, \"alpha\" : alpha, \"stuck_time\": float(sT), \"global_seed\": \"default\"}, index=[sampleNr])\n",
    "                avg_trav_time_100pct = pd.concat([avg_trav_time_100pct, df_avg_trav_time], axis = 0)\n",
    "                # calculate average traveled distance\n",
    "                avg_trav_dist = np.mean(temp[\"traveled_distance\"])\n",
    "                df_avg_trav_dist = pd.DataFrame({\"avg_trav_dist\": avg_trav_dist, \"sample_size\": \"100-pct\", \"sample_nr\": sampleNr, \"alpha\" : alpha, \"stuck_time\": float(sT), \"global_seed\": \"default\"}, index=[sampleNr])\n",
    "                avg_trav_dist_100pct = pd.concat([avg_trav_dist_100pct, df_avg_trav_dist], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa503668",
   "metadata": {},
   "source": [
    "##### Concat and write output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "07ecdd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat all\n",
    "avg_trav_time_1_100pct = pd.concat([avg_trav_time_1pct_all, avg_trav_time_5pct_all, avg_trav_time_10pct, avg_trav_time_25pct, avg_trav_time_50pct, avg_trav_time_100pct ], axis = 0)\n",
    "# write all to csv\n",
    "avg_trav_time_1_100pct.to_csv(\"/home/lola/Nextcloud/Masterarbeit/03_Outputs/avg_trav_time_all_1_100pct_samples_it0.csv\", index = False)\n",
    "\n",
    "# concat all\n",
    "avg_trav_dist_1_100pct = pd.concat([avg_trav_dist_1pct_all, avg_trav_dist_5pct_all, avg_trav_dist_10pct, avg_trav_dist_25pct, avg_trav_dist_50pct, avg_trav_dist_100pct ], axis = 0)\n",
    "# write all to csv\n",
    "avg_trav_dist_1_100pct.to_csv(\"/home/lola/Nextcloud/Masterarbeit/03_Outputs/avg_trav_dist_all_1_100pct_samples_it0.csv\", index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d8f587",
   "metadata": {},
   "source": [
    "#### Travel Time distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42e0b4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sixMinuteCategoriesUpToTwoHours(df):\n",
    "    categories = []\n",
    "    for t in df[\"trav_time2\"]:\n",
    "\n",
    "\n",
    "        if (0.0 <= t and t < 0.10):\n",
    "            categories.append(\"0:00_0:06\")\n",
    "        elif (0.10 <= t and t < 0.20):\n",
    "            categories.append(\"0:06_0:12\") \n",
    "        elif (0.20 <= t and t < 0.30):\n",
    "            categories.append(\"0:12_0:18\")\n",
    "        elif (0.30 <= t and t < 0.40):\n",
    "            categories.append(\"0:18_0:24\")\n",
    "        elif (0.40 <= t and t < 0.50):\n",
    "            categories.append(\"0:24_0:30\")\n",
    "        elif (0.50 <= t and t < 0.60):\n",
    "            categories.append(\"0:30_0:36\")  \n",
    "        elif (0.60 <= t and t < 0.70):\n",
    "            categories.append(\"0:36_0:42\")\n",
    "        elif (0.70 <= t and t < 0.80):\n",
    "            categories.append(\"0:42_0:48\")\n",
    "        elif (0.80 <= t and t < 0.90):\n",
    "            categories.append(\"0:48_0:54\")\n",
    "        elif (0.90 <= t and t < 1.00):\n",
    "            categories.append(\"0:54_1:00\")\n",
    "\n",
    "\n",
    "        elif (1.0 <= t and t < 1.10):\n",
    "            categories.append(\"1:00_1:06\")\n",
    "        elif (1.10 <= t and t < 1.20):\n",
    "            categories.append(\"1:06_1:12\") \n",
    "        elif (1.20 <= t and t < 1.30):\n",
    "            categories.append(\"1:12_1:18\")\n",
    "        elif (1.30 <= t and t < 1.40):\n",
    "            categories.append(\"1:18_1:24\")\n",
    "        elif (1.40 <= t and t < 1.50):\n",
    "            categories.append(\"1:24_1:30\")\n",
    "        elif (1.50 <= t and t < 1.60):\n",
    "            categories.append(\"1:30_1:36\")  \n",
    "        elif (1.60 <= t and t < 1.70):\n",
    "            categories.append(\"1:36_1:42\")\n",
    "        elif (1.70 <= t and t < 1.80):\n",
    "            categories.append(\"1:42_1:48\")\n",
    "        elif (1.80 <= t and t < 1.90):\n",
    "            categories.append(\"1:48_1:54\")\n",
    "        elif (1.90 <= t and t < 2.00):\n",
    "            categories.append(\"1:54_2:00\")\n",
    "\n",
    "        else: categories.append(\">2h\")\n",
    "\n",
    "    temp = pd.DataFrame({ \"categories\": categories})\n",
    "    temp = temp.sort_values(by=['categories'])\n",
    "\n",
    "    freq_6_min_cat = []\n",
    "    for cat in temp.categories.unique():\n",
    "        f = temp[(temp[\"categories\"]==cat)].shape[0]\n",
    "        freq_6_min_cat.append(f)\n",
    "    \n",
    "    trav_times_6min_cat = pd.DataFrame({\"category\":temp.categories.unique(), \"freq\": freq_6_min_cat })\n",
    "    return trav_times_6min_cat "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5857f523",
   "metadata": {},
   "source": [
    "##### 5 pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "869ec9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1pct\n",
    "\n",
    "trav_time_1pct_categories = []\n",
    "for sampleNr in range(1,11,1):\n",
    "    #       /home/lola/math_cluster/output/output-lausitz-1pct-1-fCf_sCF_0.01_gS_default_3765/lausitz-1pct-1-fCf_sCf_0.01_gS_default_3765.output_trips.csv.gz\n",
    "    path = \"/home/lola/math_cluster/output/output-lausitz-1.0-pct-1-fCf_sCF_0.01_gS_2306_3765/ITERS/it.0/lausitz-1.0-pct-1-fCf_sCF_0.01_gS_2306_3765.0.trips.csv.gz\"\n",
    "    temp = pd.read_csv(path, compression= \"gzip\", sep=\";\")\n",
    "    temp[\"trav_time\"] = pd.to_timedelta(temp.trav_time)\n",
    "    temp[\"trav_time2\"] = temp.trav_time.astype('timedelta64[s]')/  pd.Timedelta(minutes=60)\n",
    "    trav_time_cat = sixMinuteCategoriesUpToTwoHours(temp)\n",
    "    trav_time_cat.rename(columns={\"freq\": \"freq_\" + str(sampleNr)}, inplace = True )\n",
    "    trav_time_1pct_categories.append(trav_time_cat)\n",
    "trav_time_1pct_cat_all = pd.merge(trav_time_1pct_categories[0], trav_time_1pct_categories[1], on = ['category'], how='left')\n",
    "for sampleNr in range(2,10,1):\n",
    "    trav_time_1pct_cat_all = pd.merge(trav_time_1pct_cat_all, trav_time_1pct_categories[sampleNr], on = ['category'], how='left')\n",
    "\n",
    "trav_time_1pct_cat_all['mean'] = trav_time_1pct_cat_all.iloc[:,1:11].mean(axis = 1)\n",
    "trav_time_1pct_cat_all.insert(12, 'sample_size', \"1-pct\")\n",
    "trav_time_1pct_cat_all.insert(13, 'alpha', 1.0)\n",
    "trav_time_1pct_cat_all.insert(14, 'stuck_time', 30.0)\n",
    "trav_time_1pct_cat_all.insert(15,'global_seed', \"default\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a619cbf",
   "metadata": {},
   "source": [
    "##### 5 pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28d125bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trav_time_5pct_categories = []\n",
    "for sampleNr in range(1,11,1):\n",
    "    if (sampleNr == 6):\n",
    "        path = \"/home/lola/math_cluster/output/output-lausitz-5.0-pct-6-fCf_sCF_0.05_gS_4711_3765/ITERS/it.0/lausitz-5.0-pct-6-fCf_sCF_0.05_gS_4711_3765-2.0.trips.csv.gz\"\n",
    "        temp = pd.read_csv(path, compression = \"gzip\", sep = \";\")\n",
    "        temp[\"trav_time\"] = pd.to_timedelta(temp.trav_time)\n",
    "        temp[\"trav_time2\"] = temp.trav_time.astype('timedelta64[s]')/  pd.Timedelta(minutes=60)\n",
    "        trav_time_cat = sixMinuteCategoriesUpToTwoHours(temp)\n",
    "        trav_time_cat.rename(columns={\"freq\": \"freq_\" + str(sampleNr)}, inplace = True )\n",
    "        trav_time_5pct_categories.append(trav_time_cat)\n",
    "    else:     \n",
    "        path = \"/home/lola/math_cluster/output/output-lausitz-5.0-pct-\" +str(sampleNr) + \"-fCf_sCF_0.05_gS_4711_3765/ITERS/it.0/lausitz-5.0-pct-\" + str(sampleNr) + \"-fCf_sCF_0.05_gS_4711_3765.0.trips.csv.gz\"\n",
    "        temp = pd.read_csv(path, compression= \"gzip\", sep=\";\")\n",
    "        temp[\"trav_time\"] = pd.to_timedelta(temp.trav_time)\n",
    "        temp[\"trav_time2\"] = temp.trav_time.astype('timedelta64[s]')/  pd.Timedelta(minutes=60)\n",
    "        trav_time_cat = sixMinuteCategoriesUpToTwoHours(temp)\n",
    "        trav_time_cat.rename(columns={\"freq\": \"freq_\" + str(sampleNr)}, inplace = True )\n",
    "        trav_time_5pct_categories.append(trav_time_cat)\n",
    "# left join and calculate mean\n",
    "trav_time_5pct_cat_all = pd.merge(trav_time_5pct_categories[0], trav_time_5pct_categories[1], on = ['category'], how='left')\n",
    "for sampleNr in range(2,10,1):\n",
    "    trav_time_5pct_cat_all = pd.merge(trav_time_5pct_cat_all, trav_time_5pct_categories[sampleNr], on = ['category'], how='left')\n",
    "\n",
    "trav_time_5pct_cat_all['mean'] = trav_time_5pct_cat_all.iloc[:,1:11].mean(axis = 1)\n",
    "trav_time_5pct_cat_all.insert(12, 'sample_size', \"5-pct\")\n",
    "trav_time_5pct_cat_all.insert(13, 'alpha', 1.0)\n",
    "trav_time_5pct_cat_all.insert(14, 'stuck_time', 30.0)\n",
    "trav_time_5pct_cat_all.insert(15,'global_seed', \"default\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3789214",
   "metadata": {},
   "source": [
    "##### 10 pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c2f6981",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6256/3501379692.py:4: DtypeWarning: Columns (21,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp = pd.read_csv(path, compression= \"gzip\", sep=\";\")\n",
      "/tmp/ipykernel_6256/3501379692.py:4: DtypeWarning: Columns (21,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp = pd.read_csv(path, compression= \"gzip\", sep=\";\")\n",
      "/tmp/ipykernel_6256/3501379692.py:4: DtypeWarning: Columns (21,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp = pd.read_csv(path, compression= \"gzip\", sep=\";\")\n"
     ]
    }
   ],
   "source": [
    "trav_time_10pct_categories = []\n",
    "for sampleNr in range(1,11,1):\n",
    "    path = \"/home/lola/math_cluster/output/output-lausitz-10.0-pct-\" +str(sampleNr) + \"-fCf_sCF_0.1_gS_4711_3765/ITERS/it.0/lausitz-10.0-pct-\" + str(sampleNr) + \"-fCf_sCF_0.1_gS_4711_3765.0.trips.csv.gz\"\n",
    "    temp = pd.read_csv(path, compression= \"gzip\", sep=\";\")\n",
    "    temp[\"trav_time\"] = pd.to_timedelta(temp.trav_time)\n",
    "    temp[\"trav_time2\"] = temp.trav_time.astype('timedelta64[s]')/  pd.Timedelta(minutes=60)\n",
    "    trav_time_cat = sixMinuteCategoriesUpToTwoHours(temp)\n",
    "    trav_time_cat.rename(columns={\"freq\": \"freq_\" + str(sampleNr)}, inplace = True )\n",
    "    trav_time_10pct_categories.append(trav_time_cat)\n",
    "# left join and calculate mean\n",
    "trav_time_10pct_cat_all = pd.merge(trav_time_10pct_categories[0], trav_time_10pct_categories[1], on = ['category'], how='left')\n",
    "for sampleNr in range(2,10,1):\n",
    "    trav_time_10pct_cat_all = pd.merge(trav_time_10pct_cat_all, trav_time_10pct_categories[sampleNr], on = ['category'], how='left')\n",
    "\n",
    "trav_time_10pct_cat_all['mean'] = trav_time_10pct_cat_all.iloc[:,1:11].mean(axis = 1)\n",
    "trav_time_10pct_cat_all.insert(12, 'sample_size', \"10-pct\")\n",
    "trav_time_10pct_cat_all.insert(13, 'alpha', 1.0)\n",
    "trav_time_10pct_cat_all.insert(14, 'stuck_time', 30.0)\n",
    "trav_time_10pct_cat_all.insert(15,'global_seed', \"default\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a1a550",
   "metadata": {},
   "source": [
    "##### 25 pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffcfcfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/lola/math_cluster/output/output-lausitz-25.0-pct-fCf_sCF_0.25_gS_4711_3765/ITERS/it.0/lausitz-25.0-pct-fCf_sCF_0.25_gS_4711_3765.0.trips.csv.gz\"\n",
    "t_25pct = pd.read_csv(path, compression= \"gzip\", sep=\";\")\n",
    "t_25pct[\"trav_time\"] = pd.to_timedelta(t_25pct.trav_time)\n",
    "t_25pct[\"trav_time2\"] = t_25pct.trav_time.astype('timedelta64[s]')/  pd.Timedelta(minutes=60)\n",
    "trav_time_25pct_categories = sixMinuteCategoriesUpToTwoHours(t_25pct)\n",
    "trav_time_25pct_categories.rename(columns={\"freq\": \"mean\"}, inplace = True )\n",
    "trav_time_25pct_categories.insert(2, 'sample_size', \"25-pct\")\n",
    "trav_time_25pct_categories.insert(3, 'alpha', 1.0)\n",
    "trav_time_25pct_categories.insert(4, 'stuck_time', 30.0)\n",
    "trav_time_25pct_categories.insert(5,'global_seed', \"default\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2729b0cd",
   "metadata": {},
   "source": [
    "##### 50 pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f57594a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/lola/math_cluster/output/output-lausitz-50.0-pct-fCf_sCF_0.5_gS_4711_3765/ITERS/it.0/lausitz-50.0-pct-fCf_sCF_0.5_gS_4711_3765.0.trips.csv.gz\"\n",
    "t_50pct = pd.read_csv(path, compression= \"gzip\", sep=\";\")\n",
    "t_50pct[\"trav_time\"] = pd.to_timedelta(t_50pct.trav_time)\n",
    "t_50pct[\"trav_time2\"] = t_50pct.trav_time.astype('timedelta64[s]')/  pd.Timedelta(minutes=60)\n",
    "trav_time_50pct_categories = sixMinuteCategoriesUpToTwoHours(t_50pct)\n",
    "trav_time_50pct_categories.rename(columns={\"freq\": \"mean\"}, inplace = True )\n",
    "trav_time_50pct_categories.insert(2, 'sample_size', \"50-pct\")\n",
    "trav_time_50pct_categories.insert(3, 'alpha', 1.0)\n",
    "trav_time_50pct_categories.insert(4, 'stuck_time', 30.0)\n",
    "trav_time_50pct_categories.insert(5,'global_seed', \"default\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da384f30",
   "metadata": {},
   "source": [
    "##### 100 pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "718d2888",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/lola/math_cluster/output/output-lausitz-100.0-pct-fCf_sCF_1.0_gS_4711_3765/ITERS/it.0/lausitz-100.0-pct-fCf_sCF_1.0_gS_4711_3765.0.trips.csv.gz\"\n",
    "t_100pct = pd.read_csv(path, compression= \"gzip\", sep=\";\")\n",
    "t_100pct[\"trav_time\"] = pd.to_timedelta(t_100pct.trav_time)\n",
    "t_100pct[\"trav_time2\"] = t_100pct.trav_time.astype('timedelta64[s]')/  pd.Timedelta(minutes=60)\n",
    "trav_time_100pct_categories = sixMinuteCategoriesUpToTwoHours(t_100pct)\n",
    "trav_time_100pct_categories.rename(columns={\"freq\": \"mean\"}, inplace = True )\n",
    "trav_time_100pct_categories.insert(2, 'sample_size', \"100-pct\")\n",
    "trav_time_100pct_categories.insert(3, 'alpha', 1.0)\n",
    "trav_time_100pct_categories.insert(4, 'stuck_time', 30.0)\n",
    "trav_time_100pct_categories.insert(5,'global_seed', \"default\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92bae4e",
   "metadata": {},
   "source": [
    "##### Concat and write output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68dba8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trav_time_categories_all = pd.concat([trav_time_1pct_cat_all, trav_time_5pct_cat_all, trav_time_10pct_cat_all,  trav_time_25pct_categories, trav_time_50pct_categories, trav_time_100pct_categories], axis = 0)\n",
    "trav_time_categories_all.to_csv('/home/lola/Nextcloud/Masterarbeit/03_Outputs/trav_time_categories_1_100_it0.csv', index = False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
